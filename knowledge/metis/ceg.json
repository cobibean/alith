[
    {
        "id": "765607c92861a28b",
        "topic_id": "6307",
        "title": "KnightGuard: AI Powered Land NFT Intelligence & Ownership Protection",
        "url": "https://forum.ceg.vote/t/knightguard-ai-powered-land-nft-intelligence-ownership-protection/6307",
        "views": "",
        "comments": "2",
        "created_date": "Jul 11, 2025 10:32 pm",
        "latest_activity": "Jul 11, 2025 10:38 pm",
        "content": "Project Name\nKnightGuard: AI Land NFT Intelligence & Ownership Protection\nProblem Statement\nLand conflicts and fraudulent property claims remain rampant across Nigeria and many parts of Africa. Without trusted systems for verifying boundaries, land use potential, or ownership status, buyers and investors face the risk of double-selling, fake documents, or inaccessible land. There\u2019s no real-time, transparent way to check if land overlaps, is suitable for use, or is already owned.\nSolution Overview\nKnightGuard is an AI-native, onchain land intelligence and ownership system built on Hyperion. It empowers users to analyze land by submitting 4 GPS points. The system automatically checks for polygon overlaps with existing land claims (NFTs), fetches nearby infrastructure (schools, roads, banks, hospitals), and suggests the most viable land use type (residential, commercial, agricultural). Verified land is minted as an NFT with embedded metadata \u2014 including coordinates, map previews, use-case insights, and ownership attestations.\nProject Description\nKnightGuard combines real-time geospatial AI with smart contracts to provide land insight and ownership security. Core features:\nPolygon Overlap Detection: Using Turf.js and a dynamic registry of minted land NFTs, users can detect potential fraud or double-selling.\nAmenity-Based Land Use Suggestion: The AI agent queries OpenStreetMap (via Overpass API) around the land polygon to suggest if a land is suitable for farming, real estate, markets, etc.\nOnchain Metadata: All land insights are stored as part of the NFT metadata \u2014 visible on OpenSea or KnightGuard\u2019s map explorer.\nHuman-Friendly Summaries: Built-in LLM tools summarize land conditions for layman understanding.\nMinting System: Once land is verified and suitable, users can mint a LandNFT \u2014 tamper-proof and verifiable.\nFuture features include:\nGovernment registry integrations\nOnchain-powered land price feeds\nLending and farming modules for land-backed DeFi\nThis new approach brings AI + geospatial + blockchain together in a way that lets land owners, buyers, and government agencies interact meaningfully with land before purchase.\nCommunity Engagement Features\nTestable Features / Tasks:\nSubmit land polygon \u2192 receive AI analysis + use-case summary\nMint a demo LandToken after verification\nView NFT on map or OpenSea\nDetect and flag overlapping land attempts\nSubmit attestations for trusted landowners\nAI integration\nPoints System:\n+15: AI polygon analysis task\n+20: Verified NFT mint\n+10: OpenSea + Map explorer view\n+25: Flagging overlaps or invalid land\n+40: Attestation from trusted notary\n+50: Referral that completes 3+ tasks\nGamified Experience:\nLeaderboards, badges (e.g. \u201cLand Whisperer\u201d, \u201cMapper\u201d, \u201cOverlap Slayer\u201d)\nUsers earn reputation and early access to marketplace and farming zones\nOnboarding Incentive:\nEarly users unlock premium AI insights and minting discounts\nVerified landowners may join future land DeFi pools for yield\nGetting Involved\nWe\u2019re seeking:\nAI engineers (GeoAI, LLMs)\nSolidity & PostGIS devs\nSurveyors, GIS analysts, real estate lawyers\nMappers, testers, DAO builders\nWays to contribute:\nBuild AI workflows and land-agent tools\nImplement spatial overlap checking and OSM queries\nDesign token logic and dynamic metadata\nHelp train fraud detection AI on sample documents\nPromote or partner with local land ministries\nContact: Join our Telegram group, help us fix land ownership \u2014 one polygon at a time.",
        "comments_details": [
            {
                "author": "josefophe",
                "comment": "Project Name\nKnightGuard: AI Land NFT Intelligence & Ownership Protection\nProblem Statement\nLand conflicts and fraudulent property claims remain rampant across Nigeria and many parts of Africa. Without trusted systems for verifying boundaries, land use potential, or ownership status, buyers and investors face the risk of double-selling, fake documents, or inaccessible land. There\u2019s no real-time, transparent way to check if land overlaps, is suitable for use, or is already owned.\nSolution Overview\nKnightGuard is an AI-native, onchain land intelligence and ownership system built on Hyperion. It empowers users to analyze land by submitting 4 GPS points. The system automatically checks for polygon overlaps with existing land claims (NFTs), fetches nearby infrastructure (schools, roads, banks, hospitals), and suggests the most viable land use type (residential, commercial, agricultural). Verified land is minted as an NFT with embedded metadata \u2014 including coordinates, map previews, use-case insights, and ownership attestations.\nProject Description\nKnightGuard combines real-time geospatial AI with smart contracts to provide land insight and ownership security. Core features:\nPolygon Overlap Detection: Using Turf.js and a dynamic registry of minted land NFTs, users can detect potential fraud or double-selling.\nAmenity-Based Land Use Suggestion: The AI agent queries OpenStreetMap (via Overpass API) around the land polygon to suggest if a land is suitable for farming, real estate, markets, etc.\nOnchain Metadata: All land insights are stored as part of the NFT metadata \u2014 visible on OpenSea or KnightGuard\u2019s map explorer.\nHuman-Friendly Summaries: Built-in LLM tools summarize land conditions for layman understanding.\nMinting System: Once land is verified and suitable, users can mint a LandNFT \u2014 tamper-proof and verifiable.\nFuture features include:\nGovernment registry integrations\nOnchain-powered land price feeds\nLending and farming modules for land-backed DeFi\nThis new approach brings AI + geospatial + blockchain together in a way that lets land owners, buyers, and government agencies interact meaningfully with land before purchase.\nCommunity Engagement Features\nTestable Features / Tasks:\nSubmit land polygon \u2192 receive AI analysis + use-case summary\nMint a demo LandToken after verification\nView NFT on map or OpenSea\nDetect and flag overlapping land attempts\nSubmit attestations for trusted landowners\nAI integration\nPoints System:\n+15: AI polygon analysis task\n+20: Verified NFT mint\n+10: OpenSea + Map explorer view\n+25: Flagging overlaps or invalid land\n+40: Attestation from trusted notary\n+50: Referral that completes 3+ tasks\nGamified Experience:\nLeaderboards, badges (e.g. \u201cLand Whisperer\u201d, \u201cMapper\u201d, \u201cOverlap Slayer\u201d)\nUsers earn reputation and early access to marketplace and farming zones\nOnboarding Incentive:\nEarly users unlock premium AI insights and minting discounts\nVerified landowners may join future land DeFi pools for yield\nGetting Involved\nWe\u2019re seeking:\nAI engineers (GeoAI, LLMs)\nSolidity & PostGIS devs\nSurveyors, GIS analysts, real estate lawyers\nMappers, testers, DAO builders\nWays to contribute:\nBuild AI workflows and land-agent tools\nImplement spatial overlap checking and OSM queries\nDesign token logic and dynamic metadata\nHelp train fraud detection AI on sample documents\nPromote or partner with local land ministries\nContact: Join our Telegram group, help us fix land ownership \u2014 one polygon at a time."
            },
            {
                "author": "LazAI_Helper_bot",
                "comment": "This is an interesting proposal from Joseph! KnightGuard aims to tackle a significant problem in Nigeria and Africa related to land ownership and fraudulent claims, leveraging AI, geospatial data, and blockchain technology.\nHere are some of my thoughts and potential discussion points:\nProblem Validation: The problem statement is clear and well-articulated. Land conflicts and fraud are indeed major issues in many African countries.\nSolution Novelty: The combination of AI-powered geospatial analysis with NFT-based land ownership is innovative. Using Turf.js for overlap detection and OpenStreetMap for land use suggestions seems like a practical approach.\nTechnical Feasibility: While ambitious, the project appears technically feasible. The listed features and tasks are achievable with existing technologies. PostGIS could be very useful for efficiently storing and querying the geospatial data.\nCommunity Engagement: The proposed community engagement features (testable tasks, points system, gamified experience) are a good way to incentivize participation and build a strong community around the project.\nPotential Challenges:\nData Accuracy: The accuracy of the land polygon data and OpenStreetMap data is crucial. How will KnightGuard ensure the data is up-to-date and reliable?\nScalability: Handling a large number of land NFTs and geospatial queries efficiently could be a challenge.\nAdoption: Getting landowners, buyers, and government agencies to adopt the system may require significant effort.\nSuggestions:\nConsider integrating with existing land registries where possible.\nExplore using satellite imagery for land use analysis in addition to OpenStreetMap.\nFocus on building partnerships with local communities and government agencies.\nI recommend these next steps:\nInquire About Data Sources: Ask Joseph about the primary data sources for land polygons and how they plan to address data accuracy and potential discrepancies.\nDiscuss Scalability: Explore the project\u2019s plans for handling a large volume of geospatial data and NFT transactions.\nEncourage Community Feedback: Encourage other community members to provide feedback on the project and its potential impact.\nSuggest a Prototype: Building a small-scale prototype to demonstrate the core features and gather user feedback would be valuable.\nThis project has the potential to make a real difference in addressing land ownership issues in Africa. I\u2019m excited to see how it develops!"
            },
            {
                "author": "josefophe",
                "comment": "Thanks\n@LazAI_Helper_bot\n, I already have this on dev mode and would love to fit this in the hackathon aligned track."
            }
        ]
    },
    {
        "id": "a588ef262157116c",
        "topic_id": "5966",
        "title": "HyperHack Spotlight Campaign is Live",
        "url": "https://forum.ceg.vote/t/hyperhack-spotlight-campaign-is-live/5966",
        "views": "",
        "comments": "25",
        "created_date": "Jun 25, 2025 2:10 pm",
        "latest_activity": "Jul 11, 2025 6:56 pm",
        "content": "Gm Metisians, the Spotlight Campaign is here to supercharge your HyperHack journey!\nWe are giving selected project teams a chance at the $7500 bonus prize pool, $500 in marketing credit, access to guild talent, and the chance to earn tiered ecosystem rewards. The goal is to boost your visibility and help you grow real users.\nApply here\nCampaign Objective\nTo empower HyperHack teams to market their projects using a real budget. This is about helping builders grow their audience, activate users, and showcase their dApps across the Metis ecosystem.\nHow It Works\n$500 marketing credit for each project, 50 projects at maximum\n$7500 extra prize pool for top projects\nEach selected project will receive $500 in marketing credit, split into:\n$300 upfront to start your campaign\n$200 unlocked later if performance goals are met by August 1\n$500 Marketing Credit\nEach project must create a dedicated X account for their HyperHack product and have at least one marketer (internal or from the Forum Marketing Guild) who will:\nLead the project\u2019s marketing strategy\nUse the $500 to drive short-term traffic\nJoin a Vibe Session to introduce the dapp\nShare referral links via X posts to their forum showcase\nApproved Marketing Tactics:\nQuest Campaigns (TaskOn, Zealy, Magic Square): e.g. \u201cFollow + Retweet + Test dapp + Join Forum\u201d\nAMA Airdrops: Host AMAs on X and airdrop to the Metis community\nTwitter Ads: Use paid ads to boost visibility (marketer must help set this up)\nCustom Strategies: Teams are also encouraged to try any other creative ideas tailored to their product and audience\nNote: Marketer\u2019s name and focus must be listed in the application (e.g., Marketing Lead: @Handle \u2013 Focus: Memes & Spaces).\nHow We Track Performance\nProjects will be scored across three categories during July 15 to August 1:\n75% X account growth and quality (verified via TwitterAudit)\n20% user activity on your dApp (measured onchain)\n5% users driven to your Forum thread using referral links\nRewards for Top Projects\nTotal Prize Pool: $7500\nTier 1: HyperHack Spotlight Champion\n$3000 bonus for the top project\nForum pin for 14 days\nPriority DevRel support for 6 months\nNewsletter spotlight\n25 bonus points for the final judging phase\nTier 2: Growth Catalysts\n$3000 prize pool\nForum pin for 7 days\nDevRel support for 3 months\nNewsletter spotlight\n15 bonus points\nTier 3: Community Stars\n$1500 prize pool\nDevRel support for 1 month\nNewsletter spotlight\n10 bonus points\nKey Dates\nApplication period: June 25-July 8\nApplication review: July 9- 15\nCampaign period: July 15- August 1\nRules\nFunds must be used for approved marketing activities only\nBot traffic is not allowed and will be checked\nYour marketing strategy must be made public in your Forum thread\nThe Spotlight Campaign is designed to help real builders grow real audiences.\nApply here\nFor questions, reply below.\nGL to all!",
        "comments_details": [
            {
                "author": "Liametis",
                "comment": "Gm Metisians, the Spotlight Campaign is here to supercharge your HyperHack journey!\nWe are giving selected project teams a chance at the $7500 bonus prize pool, $500 in marketing credit, access to guild talent, and the chance to earn tiered ecosystem rewards. The goal is to boost your visibility and help you grow real users.\nApply here\nCampaign Objective\nTo empower HyperHack teams to market their projects using a real budget. This is about helping builders grow their audience, activate users, and showcase their dApps across the Metis ecosystem.\nHow It Works\n$500 marketing credit for each project, 50 projects at maximum\n$7500 extra prize pool for top projects\nEach selected project will receive $500 in marketing credit, split into:\n$300 upfront to start your campaign\n$200 unlocked later if performance goals are met by August 1\n$500 Marketing Credit\nEach project must create a dedicated X account for their HyperHack product and have at least one marketer (internal or from the Forum Marketing Guild) who will:\nLead the project\u2019s marketing strategy\nUse the $500 to drive short-term traffic\nJoin a Vibe Session to introduce the dapp\nShare referral links via X posts to their forum showcase\nApproved Marketing Tactics:\nQuest Campaigns (TaskOn, Zealy, Magic Square): e.g. \u201cFollow + Retweet + Test dapp + Join Forum\u201d\nAMA Airdrops: Host AMAs on X and airdrop to the Metis community\nTwitter Ads: Use paid ads to boost visibility (marketer must help set this up)\nCustom Strategies: Teams are also encouraged to try any other creative ideas tailored to their product and audience\nNote: Marketer\u2019s name and focus must be listed in the application (e.g., Marketing Lead: @Handle \u2013 Focus: Memes & Spaces).\nHow We Track Performance\nProjects will be scored across three categories during July 15 to August 1:\n75% X account growth and quality (verified via TwitterAudit)\n20% user activity on your dApp (measured onchain)\n5% users driven to your Forum thread using referral links\nRewards for Top Projects\nTotal Prize Pool: $7500\nTier 1: HyperHack Spotlight Champion\n$3000 bonus for the top project\nForum pin for 14 days\nPriority DevRel support for 6 months\nNewsletter spotlight\n25 bonus points for the final judging phase\nTier 2: Growth Catalysts\n$3000 prize pool\nForum pin for 7 days\nDevRel support for 3 months\nNewsletter spotlight\n15 bonus points\nTier 3: Community Stars\n$1500 prize pool\nDevRel support for 1 month\nNewsletter spotlight\n10 bonus points\nKey Dates\nApplication period: June 25-July 8\nApplication review: July 9- 15\nCampaign period: July 15- August 1\nRules\nFunds must be used for approved marketing activities only\nBot traffic is not allowed and will be checked\nYour marketing strategy must be made public in your Forum thread\nThe Spotlight Campaign is designed to help real builders grow real audiences.\nApply here\nFor questions, reply below.\nGL to all!"
            },
            {
                "author": "4ngel",
                "comment": "This is huge !!! Good luck to every participant, let\u2019s get it"
            },
            {
                "author": "Elenaisplaying",
                "comment": "Such a great news. Good luck everyone"
            },
            {
                "author": "i_am_supaman_lj",
                "comment": "I got a hiccup in the marketers forum ID and the Project owner forum ID. I don\u2019t really know how to find that, any form of assistance would be greatly appreciated."
            },
            {
                "author": "Ghostt",
                "comment": "You will see that on your profile, and your own forum id is\n@i_am_supaman_lj\n. If you click the @ sign you will get it."
            },
            {
                "author": "priyankg3",
                "comment": "Thats wonderful, this is the golden chance for developers to build and polish with your project with marketing as well.."
            },
            {
                "author": "i_am_supaman_lj",
                "comment": "Thanks a lot, I was actually hoping I would work with you. Since you are one of the first that saw the potential of Fracturepoint as a solution to the recent web3 gaming failure trends."
            },
            {
                "author": "i_am_supaman_lj",
                "comment": "Thanks for the help, we can go on with the plan already now right ?"
            },
            {
                "author": "Sheyda",
                "comment": "Fantastic, do you have a list of Marketers?"
            },
            {
                "author": "i_am_supaman_lj",
                "comment": "List?\nI thought only one ."
            },
            {
                "author": "i_am_supaman_lj",
                "comment": "Specified one marketer on the form Thats why I sort for one"
            },
            {
                "author": "mrwagmicto",
                "comment": "Hey everyone!\nI\u2019m looking for a marketing partner to join me on an exciting crypto project and help drive this campaign forward.\nIf you\u2019re passionate about Web3 marketing, community building, or growth hacking \u2014 let\u2019s talk!\nFeel free to DM me. Would love to connect!"
            },
            {
                "author": "Ghostt",
                "comment": "I have teamed up with him and applied to the campaign. Looking forward to the result."
            },
            {
                "author": "0xdellwatson",
                "comment": "is it possible to also co-join with other campaign ?\nDM for more exposure with our team!"
            },
            {
                "author": "arbilearn",
                "comment": "This is great opportunity"
            },
            {
                "author": "Invnex",
                "comment": "Excited, and we\u2019ve applied for Invnex."
            },
            {
                "author": "sagarjethi",
                "comment": "Such a great news. Good luck everyone"
            },
            {
                "author": "metapay_gyuha",
                "comment": "Hi! I\u2019m one of the Spotlight Campaign applicants and already submitted my form.\nI\u2019d like to submit my detailed marketing strategy as an additional document.\nCan I upload it to Google Drive and share the link here? Or should I send it via email?\nThanks a lot for this opportunity!\n\u2013\n@metapay_gyuha"
            }
        ]
    },
    {
        "id": "22684d2d7629fce2",
        "topic_id": "6304",
        "title": "How to check Earned Badges",
        "url": "https://forum.ceg.vote/t/how-to-check-earned-badges/6304",
        "views": "",
        "comments": "0",
        "created_date": "Jul 11, 2025 4:27 pm",
        "latest_activity": null,
        "content": "To check your badge status:\nGo to your profile by clicking your username at the top right corner of the forum.\nClick on the \u201cBadges\u201d section, located under the \u201cInvites\u201d tab.\nYou will be able to see all of the badges you have earned and their details.\nThis will allow you to track your progress and see if you qualify for different roles, like Guild Leader or any other special privileges within the forum!\nLearn more about Forum badge and point system: Badge and Point System User Guide",
        "comments_details": [
            {
                "author": "Sheyda",
                "comment": "To check your badge status:\nGo to your profile by clicking your username at the top right corner of the forum.\nClick on the \u201cBadges\u201d section, located under the \u201cInvites\u201d tab.\nYou will be able to see all of the badges you have earned and their details.\nThis will allow you to track your progress and see if you qualify for different roles, like Guild Leader or any other special privileges within the forum!\nLearn more about Forum badge and point system: Badge and Point System User Guide"
            }
        ]
    },
    {
        "id": "68d4c6cb134584d5",
        "topic_id": "5537",
        "title": "[MetaPay] A Circulating Basic Income Model with Digital Currency",
        "url": "https://forum.ceg.vote/t/metapay-a-circulating-basic-income-model-with-digital-currency/5537",
        "views": "",
        "comments": "33",
        "created_date": "Jun 12, 2025 11:25 pm",
        "latest_activity": "Jul 11, 2025 2:59 pm",
        "content": "[MetaPay] A Circulating Basic Income Model with Digital Currency\nOverview\nMetaPay is a programmable, circulating basic income system that distributes funds through digital wallets and recollects a fixed percentage to ensure sustainability \u2014 without raising taxes or relying on additional government budgets.\nProblem\nMost basic income proposals fail due to unrealistic funding models. They often depend on higher taxation, increasing national debt, or complex redistribution mechanisms that generate political resistance and economic inefficiencies.\nOur Solution\nMetaPay operates on a simple yet powerful loop:\nAn initial fund of 250 trillion KRW\nDistributed over 10 months (25 trillion KRW/month)\nStarting from month 10, 10% of each wallet\u2019s remaining balance is recollected at the end of each month\nThe recollected funds are used to fund the next cycle\nThis creates a self-sustaining system with zero net government burden and maximum benefit for citizens.\nKey Features\nAll payments and recollections are processed exclusively via digital currency\nWallets automatically split payments: 50% MetaPay + 50% cash or card\nNo restrictions on how the income is used\nHigher-income users contribute more through greater spending, while lower-income users retain full benefit\nFully trackable, automated, and transparent\nWhat We Need\nWe are seeking collaborators who can support:\nSmart contract development\nTokenomics modeling and analysis\nUX/UI simulation and digital wallet architecture\nStress testing on the Hyperion Testnet\nLet\u2019s bring MetaPay to life \u2014 and demonstrate how real-world programmable basic income can scale sustainably and fairly.",
        "comments_details": [
            {
                "author": "metapay_gyuha",
                "comment": "[MetaPay] A Circulating Basic Income Model with Digital Currency\nOverview\nMetaPay is a programmable, circulating basic income system that distributes funds through digital wallets and recollects a fixed percentage to ensure sustainability \u2014 without raising taxes or relying on additional government budgets.\nProblem\nMost basic income proposals fail due to unrealistic funding models. They often depend on higher taxation, increasing national debt, or complex redistribution mechanisms that generate political resistance and economic inefficiencies.\nOur Solution\nMetaPay operates on a simple yet powerful loop:\nAn initial fund of 250 trillion KRW\nDistributed over 10 months (25 trillion KRW/month)\nStarting from month 10, 10% of each wallet\u2019s remaining balance is recollected at the end of each month\nThe recollected funds are used to fund the next cycle\nThis creates a self-sustaining system with zero net government burden and maximum benefit for citizens.\nKey Features\nAll payments and recollections are processed exclusively via digital currency\nWallets automatically split payments: 50% MetaPay + 50% cash or card\nNo restrictions on how the income is used\nHigher-income users contribute more through greater spending, while lower-income users retain full benefit\nFully trackable, automated, and transparent\nWhat We Need\nWe are seeking collaborators who can support:\nSmart contract development\nTokenomics modeling and analysis\nUX/UI simulation and digital wallet architecture\nStress testing on the Hyperion Testnet\nLet\u2019s bring MetaPay to life \u2014 and demonstrate how real-world programmable basic income can scale sustainably and fairly."
            },
            {
                "author": "priyankg3",
                "comment": "Hello\n@metapay_gyuha\n, What happens if users withdraw all funds from their wallet before the 10% recollection?\nHow does the automatic 50/50 split with MetaPay and fiat work at merchant checkouts?"
            },
            {
                "author": "han",
                "comment": "Thanks for sharing the MetaPay vision. really inspiring! With 10% of my wallet balance being recollected monthly, will there be a transparent interface to track this process? Also, can the recollection rate be personalized based on my spending behavior?"
            },
            {
                "author": "metapay_gyuha",
                "comment": "Thank you for your great question and your interest in MetaPay!\nLet me answer each part in detail:\n1. Transparent Interface for Recollection Tracking\nMetaPay is designed so that all users can track both the distribution and recollection of funds in real time through their digital wallets.\nAt the end of each month, users will be able to clearly see:\nThe amount recollected (10% of remaining balance)\nThe amount distributed\nCurrent wallet balance\nFull transaction and recollection history\nMonthly reports will also be provided via the mobile app or web-based wallet interface to ensure full transparency.\n2. About Personalizing the Recollection Rate\nMetaPay maintains a fixed 10% recollection rate for all users.\nThis is because the recollected amount is directly used as the fund for the next month\u2019s distribution.\nIf the rate were to vary by individual, it would break the balance of this self-sustaining cycle and threaten the long-term stability of the system.\nHowever, small demographic changes (such as births or deaths) can be handled through government budget adjustments or annual fiscal planning, without affecting the core 10% structure.\nIf you\u2019re curious about the full MetaPay model, please feel free to visit our YouTube channel.\nWe\u2019ve uploaded videos that explain the core mechanics and philosophy of MetaPay in detail:\nMain Intro Video\nMetaPay \u2013 A Circulating Basic Income: Whose Time Are You Living?\nhttps://youtu.be/e4lH_uGN-ck\nVisit Our Channel\nhttps://www.youtube.com/@MetaPayProject\nThank you again for engaging with the project. If you have more questions, we\u2019d love to continue the conversation!\n\u2014 MetaPay Project Team"
            },
            {
                "author": "metapay_gyuha",
                "comment": "Thank you for your thoughtful questions! Let me explain each point clearly.\n1. What happens if a user withdraws all MetaPay before the 10% recollection at the end of the month?\nMetaPay is a closed-loop digital system that cannot be freely withdrawn as cash.\nAll MetaPay balances are managed within your digital wallet and cannot be transferred directly to others or exchanged into fiat currency.\nEven if you attempt to use up all of your balance before the end of the month, the system will calculate the recollection amount based on your wallet balance at that exact time (e.g., 10% of the remaining amount on the last day of the month).\nThis ensures fairness and sustainability, regardless of spending patterns.\n2. How does the automatic 50/50 split payment work between MetaPay and fiat currency?\nWhenever you make a payment at a registered merchant, your wallet automatically splits the transaction:\n50% is paid using MetaPay, and 50% using your existing payment method (cash, credit, etc.).\nThis is enforced by the system and does not require manual input by the user or merchant, maintaining simplicity and compliance.\nIt also ensures MetaPay is circulated and reclaimed properly within the system.\nWant to explore the MetaPay model in detail?\nCheck out the official video and YouTube channel, where we explain the philosophy and mechanism of MetaPay.\nIntro Video\nMetaPay Circulating Basic Income \u2013 \u201cWhose time is it, really?\u201d\n\uba54\ud0c0\ud398\uc774\uc21c\ud658\ud615 \uae30\ubcf8\uc18c\ub4dd : \ub2f9\uc2e0\uc758 \uc2dc\uac04\uc740 \ub204\uad6c\uc758 \uac83\uc785\ub2c8\uae4c?\nFull Channel\nYouTube\nMetaPay Project\nShare your videos with friends, family, and the world\nWe believe MetaPay is not just about distributing money\u2014\nit\u2019s about restoring your time, freedom, and dignity.\nLet\u2019s build this future together."
            },
            {
                "author": "priyankg3",
                "comment": "Thanks for the detailed explanation! That clears up both points really well.\nWill definitely check out the video to understand the bigger picture better. Appreciate the quick response!"
            },
            {
                "author": "metapay_gyuha",
                "comment": "[HyperHack Submission] MetaPay \u2013 A Circular Basic Income Simulator on Web3\nProject Name: MetaPay\nOne-line Description:\nA self-sustaining basic income simulator using smart contracts and Web3 wallets to solve inequality, restore political trust, and reduce welfare inefficiencies.\nProblem Statement\nMost basic income models struggle due to three major reasons:\nUnsustainable funding (e.g., new taxes or debt)\nPublic distrust in fair distribution\nDisruption to existing welfare systems\nMetaPay introduces a fully digital, autonomous solution that avoids new taxation, ensures transparency via smart contracts, and operates in parallel with current welfare structures.\nSolution\nMetaPay distributes \u20a9500,000 (~$370) monthly to 50 million citizens via Web3 wallets.\nAll transactions are digitally trackable\nSmart contracts govern issuance, use, and recollection\nAfter 10 months, 10% of remaining wallet balances are recollected to fund the next round, creating a circular, self-replenishing cycle\nUser Flow (Example)\nA citizen receives \u20a9500,000 in their MetaPay wallet\nThey make a purchase\u2014payment is split 50:50 between MetaPay and cash/card\nUnused MetaPay remains untouched\nAt the end of month 10, 10% of the remaining amount is recollected\nThat amount funds the next distribution\nNo expiration, no loss if spent\u2014just gentle nudging toward use\nSimulation Results (Based on Pilot Assumptions)\n84% average utilization rate per user/month\n19% increase in local SME revenue\nEstimated \u20a92.3 trillion additional tax revenue in first year\nNo inflation impact due to controlled injection/recollection loop\n(Detailed modeling in SSRN paper)\nTech Stack\nWeb3 Wallets (MetaMask, Hyperion Wallet)\nEVM-Compatible Smart Contracts (ERC20-like logic)\nAlith ZK-ID Integration (for Sybil resistance)\nAI Policy Simulation Engine (Python ML)\nUX/UI Design Tools (Figma, no-code prototypes)\nAlith ZK-ID Scenario\nTo ensure fairness in decentralized networks:\nEach wallet is linked to a unique identity via Zero-Knowledge Proofs\nNo personal data shared\u2014privacy fully preserved\nPrevents wallet duplication or \u201cSybil attacks\u201d during distribution\nThis enables equitable and secure distribution even across unbanked or pseudonymous populations.\nWhy MetaPay Matters\nNo new taxes, no system overhaul\nTransparent governance via open-source contracts\nRestores political trust and boosts civic engagement\nReduces unemployment without discouraging job-seeking\nWorks alongside existing welfare programs\nDemo & Repos\nDemo video: https://youtu.be/e4lH_uGN-ck\nGitHub: MetaPay \u2013 A Web3-based Circular Basic Income Simulator\nTestnet dApp: MetaPay UI Demo\nPilot & Collaboration Plan\nWe are seeking to pilot MetaPay with:\nSmall EU municipalities (e.g., Estonia, Portugal)\nDecentralized communities or DAOs\nNGOs & academic institutions interested in Web3-driven policy\nLet\u2019s test a real-world basic income loop without the usual frictions.\nForum ID: metapay_gyuha\nLooking Forward\nMetaPay isn\u2019t just a simulator\u2014it\u2019s a prototype for real policy.\nJoin us to co-create the next generation of digital, fair, and circular basic income.\nLet\u2019s build not only systems, but trust.\nDM or comment below if you\u2019d like to collaborate, test, or fork MetaPay."
            },
            {
                "author": "metapay_gyuha",
                "comment": "MetaPay Circulation Structure Visualization (Updated)\nMetaPay is not just about distribution\u2014it is a self-sustaining, circular basic income model that continuously operates through automatic recollection and redistribution using digital currency.\nWithout any need for long-term tax increases or additional government spending, the initial KRW 250 trillion investment enters an infinite loop of monthly distribution and recollection\u2014creating a durable, automated system.\nThe chart below visualizes how the MetaPay system operates over time:\nInitial Capital: KRW 250 trillion (distributed over 10 months at KRW 25 trillion per month)\nImportantly, this initial capital is not a sunk cost.\nAs basic income boosts consumption and economic activity, increased tax revenue can be used to repay the original KRW 250 trillion\u2014without cutting existing programs or raising new taxes.\nRecollection Start: From month 10.5 onward, 10% of each wallet\u2019s remaining balance is automatically recollected at the end of every month\nRecollected Funds: Fully reused as the source of next month\u2019s distribution\nResult: A perfectly circular economic loop with zero net fiscal burden\n\u201cThis model can be piloted in small EU nations by adjusting the distribution-to-recollection ratio to fit local GDP.\u201d\nChart Breakdown\nGreen Bars (Distribution): KRW 25 trillion distributed each month\nRed Bars (Recollection): KRW 25 trillion recollected monthly starting at month 10.5\nBlue Line (Cumulative Balance): Tracks the total circulating balance\n\u2192 It rises for the first 10 months, then stabilizes at KRW 250 trillion\n\u2192 This equilibrium is maintained as long as distribution and recollection stay synchronized.\nGlobal Applicability & Pilot Readiness\nMetaPay is designed with a simple mathematical formula that is independent of any specific country\u2019s tax laws or welfare system:\nDistribution (B) = Fixed amount (e.g. 25T)\nRecollection (R) = 10% of wallet balance at the end of the month\nIf B = R \u2192 The system becomes self-sustaining\nBecause of this, MetaPay can be implemented anywhere by adjusting only the base amount according to local GDP or population. For instance:\nA small EU country with 5 million people could adjust the monthly benefit per person according to national GDP, while keeping the 10% recollection rule intact.\nThis makes MetaPay ideal for pilot testing in:\nSmall EU member states (e.g., Estonia, Slovenia, Portugal)\nDecentralized communities or digital welfare zones\nInternational policy labs with limited fiscal risk\nMetaPay proves that basic income can be self-sustaining, programmable, and globally adaptable\u2014without requiring new taxes.\nLet\u2019s co-create a fairer digital future that begins with circulation, not debt.\nComing next: Technical Architecture & DID-based Identity Integration (Bonus Track)"
            },
            {
                "author": "metapay_gyuha",
                "comment": "MetaPay Technical Architecture & Identity Layer (Bonus Track)\nTo complement the policy design, this section introduces the technical backbone of MetaPay\u2014integrating decentralized identity, biometric verification, and programmable smart contracts.\nThis architecture enables a secure, automated, and globally scalable basic income system using blockchain and verifiable digital identity.\nSystem Overview\nMetaPay operates through the following core technical layers:\nBiometric Verification (Alice)\nFace recognition ensures each user holds only one MetaPay Wallet (1-person-1-wallet).\nDecentralized ID (DID) + Verifiable Credential (VC)\nAfter facial verification, users are issued a VC that proves their identity without exposing private information.\nSmart Contract\nGoverns income distribution, 10% recollection, and identity verification logic.\nMetaPay Wallet\nAutomatically receives monthly income and recollects 10% of the remaining balance.\nOff-chain Ledger\nOptionally used by governments or institutions to transparently log transactions without storing personal data.\nFlow Summary\nAlice verifies the user\u2019s face during onboarding.\nA Verifiable Credential (VC) is issued and linked to the user\u2019s DID.\nThe VC is submitted to the Smart Contract for validation.\nOnce approved, the contract distributes monthly income to the user\u2019s MetaPay Wallet.\nAt the end of each month, 10% of the wallet\u2019s remaining balance is automatically recollected.\nAll events are transparently recorded to a government or institutional ledger (if applicable).\nTech Stack\nSmart Contracts: Solidity-based, Ethereum-compatible logic\nID Layer: DID + VC + biometric (Alice) integration\nZKP (Zero-Knowledge Proofs): Enables identity verification without revealing personal data\nWallet: MetaMask / Hyperion Wallet customized for MetaPay circulation\nLedger: Off-chain transparency layer for auditing (regional option)\nGlobal Scalability\nThis architecture supports:\nCross-border pilot projects in digital ID-ready regions (e.g., Estonia, Slovenia, Portugal)\nFull compliance with EU Digital Identity Wallet (EUDI Wallet) standards\nAdjustable payout amounts based on national GDP, while maintaining the fixed 10% recollection structure\nArchitecture Diagram \u2013 Identity-Integrated Circulation Flow\nVisual representation of MetaPay\u2019s end-to-end system:\nFacial verification (Alice)\nCredential issuance (DID + VC)\nSmart contract logic\nWallet automation\nTransparent recordkeeping\nDiagram: Secure identity-linked basic income distribution and recollection process\nMetaPay is not just a basic income system\u2014\nIt\u2019s verifiable, programmable, and globally adaptable by design.\nLet\u2019s co-create a transparent economic future that begins with circulation, not debt.\nArchitecture Diagram \u2013 Identity-Integrated Circulation Flow\nDiagram: Secure identity-linked basic income distribution and recollection process"
            },
            {
                "author": "priyankg3",
                "comment": "Hello\n@metapay_gyuha\n, It would be great to see your project featured in a Vibe session! If you\u2019re interested in applying and showcasing then, I\u2019d really love to see how Hyperion is involved in your project\u2019s vision. If you have a demo to show us, that would be even better."
            },
            {
                "author": "metapay_gyuha",
                "comment": "Thank you\n@priyankg3\nfor your kind message \u2014 I\u2019m honored that MetaPay is being considered for a Vibe session!\nTo be transparent, the demo DApp is currently in development, and we\u2019ve encountered a technical issue during Remix deployment. That said, the core logic \u2014 including distribution, recollection, and the self-sustaining loop \u2014 has already been implemented.\nThe simulation is designed to demonstrate how Hyperion-compatible wallets and smart contracts automate the cycle. We\u2019re actively working to resolve the issue and finalize a testnet version.\nI\u2019d love to share the demo here as soon as it\u2019s ready.\nAppreciate the opportunity and look forward to contributing further!"
            },
            {
                "author": "metapay_gyuha",
                "comment": "MetaPay \u2013 A Circulating Basic Income Model Using Digital Currency\nTechnical Overview for Ideathon Submission\n1. Project Summary\nProject Name: MetaPay\nDomain: Web3, Digital Currency, Public Policy, Universal Basic Income, Privacy (ZK-ID)\nMetaPay is a programmable, circulating basic income system that enables sustainable redistribution without raising taxes. It operates entirely through digital currency and blockchain infrastructure, ensuring economic inclusion and policy transparency. Importantly, MetaPay is designed to work alongside existing welfare programs\u2014supporting, not replacing, traditional social protections.\n2. Technical Structure & Flow\nCore Mechanism:\nAn initial capital of 250 trillion KRW is distributed over 10 months (25 trillion/month) via Web3 wallets. From month 11, 10% of each wallet\u2019s remaining balance is automatically recollected and reused for the next cycle\u2014forming an infinite redistribution loop that requires no additional taxes or external funding.\nDistribution Cycle:\nEach citizen receives 500,000 KRW per month in MetaPay\nPayments are made through digital wallets\nAll purchases are auto-split: 50% MetaPay + 50% fiat (cash, card, etc.)\nPayment patterns are transparently trackable, no manual input needed\nRecollection Cycle:\nAt the end of each month (starting month 11), 10% of leftover wallet balance is recollected\nThese funds become the source of the next month\u2019s universal distribution\nNo penalties or restrictions\u2014recollection applies only to unused MetaPay\nZK-ID Integration: To ensure fairness and prevent abuse:\nFacial recognition via Alice biometric layer during onboarding\nDID (Decentralized ID) and VC (Verifiable Credential) issued per person\nSmart contracts verify uniqueness (1 wallet per person) without revealing private data\n3. Policy Relevance & Feasibility\nSubmitted to South Korea\u2019s national digital democracy platform\nPolitically safe: No interference with welfare or pension systems\nTechnically versatile: Works with national ID infrastructure or ZK-ID-only regions\nFinancially circular: System sustains itself without future tax increases\n4. Public Engagement & Tools\nTestnet-based simulator (distribute \u2192 recollect \u2192 redistribute)\nYouTube explainer: \u201cWhose Time Are You Living?\u201d\nAll smart contracts are open-source and modular (on GitHub)\nSystem interoperable with Polygon ID, Semaphore, Worldcoin ZK stack\n5. Technical Stack\nSmart Contracts: Solidity (ERC20 logic, programmable recollection)\nWallet: MetaMask, Hyperion Wallet (custom UI with auto-split logic)\nIdentity: Biometric face scan + DID + VC (ZK-proof)\nLedger: Optional off-chain ledger for institutional use\nFrontend: React, Web3.js\nSimulation: Vercel-hosted interactive DApp\nMetaPay is more than a prototype. It\u2019s a scalable blueprint for fair, transparent, and programmable digital basic income."
            },
            {
                "author": "metapay_gyuha",
                "comment": "MetaPay \u2013 Visual Tech Summary\nThis 1-page summary illustrates how MetaPay enables a sustainable circular basic income using digital wallets, DID/ZK-ID verification, and smart automated fund recycling. Designed to be clear for both developers and policymakers.\nKey structure:\n\u2022 \u20a925T distributed monthly\n\u2022 10% recollected from wallet balances every month-end\n\u2022 Reused for next cycle \u2013 no tax increase needed\n\u2022 Verified via secure ZK-ID logic\nPDF Download: MetaPay_Visual_TechSummary_EN.pdf\nContact: metapay.gyuha@gmail.com\nYouTube Explainer: https://youtu.be/e4IH_uGN-ck"
            },
            {
                "author": "metapay_gyuha",
                "comment": "MetaPay \u2013 Circulating Basic Income DApp: Full Test Completed\nFollowing the previous policy design submission, we have now completed a working DApp prototype of the MetaPay model \u2013 a self-sustaining, tax-free basic income system based on monthly distribution and digital recollection.\nThe DApp was developed using:\nSolidity for smart contract logic\nVite + React for front-end\nMetaMask integration for all transactions (wallet connection, signing, gas usage)\nEthers.js for contract interaction\nLocal simulation of wallet ecosystem (1 owner + 5 virtual wallets)\nThe core mechanism is as follows:\nEvery month, the owner (government) distributes \u20a9500,000 worth of basic income to each citizen\u2019s wallet.\nOn the 10th month, 10% of the remaining balance is automatically recollected per wallet.\nThis collected amount (\u20a925 trillion equivalent in simulation) becomes the next month\u2019s funding source.\nThe cycle then repeats endlessly without the need for new taxation or deficit spending.\nIn the simulation:\nWe distributed funds 5 times to 5 wallets.\nEach distribution reduced the owner balance and increased user balances accurately.\nAfter triggering collect(), exactly 10% of each balance was recollected and transferred back to the owner.\nAll balances were checked in real-time through the UI.\nMetaMask popped up for every transaction (signing/confirmation), confirming real smart contract interaction.\nWe recorded a 2-minute full-screen demo video showing:\nWallet connection\n5x distributions (with UI & balance changes)\nFinal recollection (with updated balances and contract status)\nMetaMask interactions\nVisual proof of automatic logic and gas-based validation\nThis prototype reflects the technical feasibility of the architecture I submitted in the Bonus Track, including:\nIdentity-linked DID logic (to be integrated later)\nTransparent on-chain tracking\nPeriodic smart contract triggers\nReal wallet-based simulation of macro-scale economy\nMetaPay aims to solve a universal economic challenge: how to provide universal basic income without additional taxation or inflation, while ensuring transparency and long-term sustainability.\nI\u2019d love to present this prototype in an unofficial Vibe Session, if possible. Please let me know if that could be arranged\nThe video demo and DApp can be shared upon request. Feedback and collaboration welcome!"
            },
            {
                "author": "metapay_gyuha",
                "comment": "Can Basic Income Work Without Taxes?\nMetaPay DApp Simulation Completed \u2013 Feedback Welcome\nHi HyperHack team and community\nI\u2019ve developed a DApp prototype of the MetaPay Circulating Basic Income Model, which demonstrates a structure where a single initial fund circulates permanently without new taxes.\nThis post shares our simulation results and invites your feedback on the current build.\nTL;DR\nDistributed \u20a9500,000 to each of 5 wallets (5 rounds tested)\n10% recollection per wallet works as expected\nReal-time UI updates + MetaMask integration confirmed\nAll actions are manually triggered via buttons\nFeedback requested on real wallet usage & automated logic\nWhat Works in the Current Version\nThe admin wallet (government) successfully distributed \u20a9500,000 to each of 5 test wallets, five times\nOn clicking collect(), 10% of each wallet\u2019s balance was recollected and returned to the admin wallet\nBoth distribution and recollection are executed manually via user-triggered buttons\nThe demo video shows 5 rounds of distribution followed by 1 recollection, all via visible button clicks\nAll balances updated in real-time through the UI, and all transactions were processed via MetaMask with proper gas fees and confirmation\nSmart Contract Core Logic\ndistribute() \u2013 sends \u20a9500,000 to each user in the list\ncollect() \u2013 recalls 10% of each wallet\u2019s current balance\nBalances are stored in: mapping(address => uint256) public balanceOf\nAll actions require MetaMask signature and gas confirmation\nWhy We Used a Simplified Test Setup\nTo ensure stability and repeatability, the simulation used 5 hard-coded virtual wallet addresses\nInitial tests with real MetaMask wallets encountered intermittent issues (e.g., gas estimation failure, RPC errors)\nSo, we focused first on verifying the core distribution-recollection loop in a controlled environment\nWhat\u2019s Next\nIntegrate real MetaMask-connected user wallets\nAdd DID or ZK-based identity verification\nImplement scheduled/condition-based triggers for distribution & recollection\nScale test with 100+ wallets for full simulation and stress testing\nDemo Video (2 minutes)\nThe video demonstrates how MetaPay works in practice:\nWallet connection \u2192 5x distribution via button clicks \u2192 1 recollection \u2192 UI balance updates \u2192 MetaMask confirmations\nWatch the Demo (Google Drive)\nFeedback Requested\nIf you have a moment, we\u2019d really appreciate your thoughts on:\nIs it acceptable to use hard-coded virtual wallets for PoC simulations at this stage? (Yes/No)\nAny known tips or best practices for stabilizing real wallet use in test environments?\nDo you recommend specific tools (e.g., Chainlink, schedulers) for automating periodic smart contract execution?\nMetaPay is an experimental attempt to turn a tax-free, self-sustaining basic income system into functioning code.\nWe know it\u2019s not perfect yet, but we hope it sparks curiosity and collaboration.\nThank you very much for your time"
            },
            {
                "author": "metapay_gyuha",
                "comment": "Can Basic Income Work Without Taxes?\nMetaPay DApp Simulation Completed \u2013 Feedback Welcome\nHi HyperHack team and community\nI\u2019ve developed a DApp prototype of the MetaPay Circulating Basic Income Model, which demonstrates a structure where a single initial fund circulates permanently without new taxes.\nThis post shares our simulation results and invites your feedback on the current build.\nTL;DR\nDistributed \u20a9500,000 to each of 5 wallets (5 rounds tested)\n10% recollection per wallet works as expected\nReal-time UI updates + MetaMask integration confirmed\nAll actions are manually triggered via buttons\nFeedback requested on real wallet usage & automated logic\nWhat Works in the Current Version\nThe admin wallet (government) successfully distributed \u20a9500,000 to each of 5 test wallets, five times\nOn clicking collect(), 10% of each wallet\u2019s balance was recollected and returned to the admin wallet\nBoth distribution and recollection are executed manually via user-triggered buttons\nThe demo video shows 5 rounds of distribution followed by 1 recollection, all via visible button clicks\nAll balances updated in real-time through the UI, and all transactions were processed via MetaMask with proper gas fees and confirmation\nSmart Contract Core Logic\ndistribute() \u2013 sends \u20a9500,000 to each user in the list\ncollect() \u2013 recalls 10% of each wallet\u2019s current balance\nBalances are stored in: mapping(address => uint256) public balanceOf\nAll actions require MetaMask signature and gas confirmation\nWhy We Used a Simplified Test Setup\nTo ensure stability and repeatability, the simulation used 5 hard-coded virtual wallet addresses\nInitial tests with real MetaMask wallets encountered intermittent issues (e.g., gas estimation failure, RPC errors)\nSo, we focused first on verifying the core distribution-recollection loop in a controlled environment\nWhat\u2019s Next\nIntegrate real MetaMask-connected user wallets\nAdd DID or ZK-based identity verification\nImplement scheduled/condition-based triggers for distribution & recollection\nScale test with 100+ wallets for full simulation and stress testing\nDemo Video (2 minutes)\nThe video demonstrates how MetaPay works in practice:\nWallet connection \u2192 5x distribution via button clicks \u2192 1 recollection \u2192 UI balance updates \u2192 MetaMask confirmations\nWatch the Demo (Google Drive)\nFeedback Requested\nIf you have a moment, we\u2019d really appreciate your thoughts on:\nIs it acceptable to use hard-coded virtual wallets for PoC simulations at this stage? (Yes/No)\nAny known tips or best practices for stabilizing real wallet use in test environments?\nDo you recommend specific tools (e.g., Chainlink, schedulers) for automating periodic smart contract execution?\nMetaPay is an experimental attempt to turn a tax-free, self-sustaining basic income system into functioning code.\nWe know it\u2019s not perfect yet, but we hope it sparks curiosity and collaboration.\nThank you very much for your time"
            },
            {
                "author": "metapay_gyuha",
                "comment": "@han\nHello! I wanted to kindly bring to your attention a feedback request I shared above on the MetaPay DApp simulation. It\u2019s a PoC exploring tax-free basic income through digital currency. If you have a moment to take a look or share any insights, it would mean a lot. Thank you in advance!"
            },
            {
                "author": "han",
                "comment": "Thanks for the reminder! I\u2019ll check out the MetaPay DApp simulation soon and share my thoughts. Appreciate you looping me in!"
            },
            {
                "author": "metapay_gyuha",
                "comment": "MetaPay \u2013 Looking for UI/UX feedback and simulation testers!\nHi builders and thinkers\nI\u2019m currently working on MetaPay, a Web3-based circular basic income simulator designed to prove that Universal Basic Income (UBI) can be sustainable \u2014 without raising taxes.\nWhat is MetaPay?\nMost UBI models struggle with:\nLack of sustainable funding\nTax burdens and redistribution resistance\nOne-way payouts with no structural loop\nMetaPay solves this through a self-sustaining cycle:\nDistribute 500 MetaPay tokens monthly to users\nReclaim 10% of unspent MetaPay at the end of each round\nUse reclaimed tokens to fund the next round\n\u2192 A repeatable \u201cDistribute \u2192 Reclaim \u2192 Redistribute\u201d loop\n\u2192 Inflation-proof, transparent, and gamified via smart contracts\nTech Stack\nVite + React + ethers.js (Frontend)\nSolidity (EVM Smart Contract)\nManual wallet simulation for now (Next: full automation)\n10 test wallets simulate circulation\nFull code & ABI on GitHub\nResources\nLive DApp (manual simulation):\nhttps://meta-pay.vercel.app\nGitHub repo:\nhttps://github.com/metapay-creator/MetaPay\nDemo video:\nhttps://drive.google.com/file/d/1e-N4DTBXr-xJYKlSI05Vw90m7eNmLPCQ/view\nYouTube intro (Concept & simulation):\nhttps://youtu.be/e4lH_uGN-ck\nI Need Help With:\nUI/UX feedback for wallet view + token flow clarity\nSuggestions for gamification (leaderboard? badges?)\nHelp with animation, dashboard graphs or time-loop UI\nAny thoughts on economic/policy realism & terminology\nI\u2019m also planning a real-time simulation event (with 10 users, multiple rounds over 20 minutes). If you\u2019re interested, let me know \u2014 you\u2019ll receive a MetaPay test wallet and get featured on X\nComment or DM if you want to test, collaborate, or just share ideas.\nLet\u2019s build something that can shift real-world policy with transparent code\n\n#HyperHack #MetaPay #BasicIncome #Web3 #SocialImpact #Hackathon #BuildInPublic"
            },
            {
                "author": "metapay_gyuha",
                "comment": "Project: MetaPay \u2013 Circulating Basic Income with Smart Contracts\nMetaPay is a self-sustaining basic income system built on smart contracts and digital currency.\nIt distributes a fixed amount monthly to citizen wallets and recollects a small portion of unused balances to fund future payments.\nThis creates a sustainable economic loop without requiring additional taxation.\nGitHub (Source code): GitHub - metapay-creator/MetaPay-\nDemo Video: Link will be posted after the Vibe session (July 2nd)\nTest DApp: Not deployed yet \u2013 available in GitHub repository\nFeedback and collaboration are always welcome!"
            }
        ]
    },
    {
        "id": "22f5b76c8df4b927",
        "topic_id": "5532",
        "title": "FlappyRoyale, a fully on-chain, real-time multiplayer game inspired by Flappy Bird, with high-stakes mini matches of five players",
        "url": "https://forum.ceg.vote/t/flappyroyale-a-fully-on-chain-real-time-multiplayer-game-inspired-by-flappy-bird-with-high-stakes-mini-matches-of-five-players/5532",
        "views": "",
        "comments": "6",
        "created_date": "Jun 12, 2025 7:46 pm",
        "latest_activity": "Jul 11, 2025 1:25 pm",
        "content": "Project Name\nFlappyRoyale\nProblem Statement\nCasual blockchain gaming often lacks real-time multiplayer competitiveness and accessible, meaningful on-chain rewards. Existing games are either overly complex or too passive, failing to attract users seeking fast, skill-based action with real crypto incentives. There\u2019s a need for simple, fun, and competitive games that reward performance in a transparent and decentralized way.\nSolution Overview\nFlappyRoyale is a fully on-chain, real-time multiplayer game inspired by Flappy Bird, with high-stakes mini matches of five players. Players stake a small amount of METIS to join each round, and the winner takes the pot. The game adds true competitiveness and ownership to casual gaming, rewarding skill and performance on-chain. With customizable skins, backgrounds, and pipes available via earned in-game currency, FlappyRoyale blends fun, fairness, and financial incentives in a way only blockchain allows.\nProject Description\nFlappyRoyale is a competitive multiplayer version of the classic Flappy Bird, built fully on-chain using the METIS blockchain. In each match, 5 players stake a small amount of METIS (e.g., $0.1) to join. The player who survives the longest wins the pooled stake (e.g., $0.5), making every game a high-stakes, skill-based micro-competition. Users can also create custom lobbies with higher stakes, allowing players to define the value they want to play for.\nThe game rewards participation with an in-game token, Golden Eggs, earned after each round, which can be used to purchase cosmetic upgrades like bird skins, backgrounds, or pipe styles. This creates a sense of progression and personalization. All gameplay logic and staking/reward mechanisms are handled fully on-chain for transparency and fairness.\nCommunity Engagement Features\nTo onboard users and gamify the platform, we will implement:\nTestable Tasks\nComplete your first match\nWin a game\nCustomize your bird with in-game currency\nCreate a custom game lobby\nRefer a friend who plays a match\nStake METIS in a higher-tier match\nGolden Eggs ($EGGS) token system\n10 EGGS for a win\n15 EGGS for customizing your bird\n30 EGGS for referring a friend\nBonus 50 EGGS for joining a high-stakes match\nGamification\nUsers will earn points for each action, which can be displayed on a leaderboard and redeemed for cosmetic items or exclusive match access. This creates a sticky experience and encourages repeated engagement.\nOnboarding Incentive\nBy providing a progression system and visible rewards for participation, users are incentivized to try every feature and invite others, building a thriving and competitive community.\nGetting Involved\nRight now, we\u2019re looking for suggestions, feedback, and early supporters. If you\u2019re excited about FlappyRoyale, here\u2019s how you can contribute:\nShare ideas for game mechanics, skins, or in-game economy\nHelp shape the reward and staking system with your input\nProvide feedback as we build the first version\nOnce the game is ready, you\u2019ll be among the first to test, play, and compete. Early supporters may also receive exclusive cosmetics or perks for helping us get off the ground.",
        "comments_details": [
            {
                "author": "rafael-abuawad",
                "comment": "Project Name\nFlappyRoyale\nProblem Statement\nCasual blockchain gaming often lacks real-time multiplayer competitiveness and accessible, meaningful on-chain rewards. Existing games are either overly complex or too passive, failing to attract users seeking fast, skill-based action with real crypto incentives. There\u2019s a need for simple, fun, and competitive games that reward performance in a transparent and decentralized way.\nSolution Overview\nFlappyRoyale is a fully on-chain, real-time multiplayer game inspired by Flappy Bird, with high-stakes mini matches of five players. Players stake a small amount of METIS to join each round, and the winner takes the pot. The game adds true competitiveness and ownership to casual gaming, rewarding skill and performance on-chain. With customizable skins, backgrounds, and pipes available via earned in-game currency, FlappyRoyale blends fun, fairness, and financial incentives in a way only blockchain allows.\nProject Description\nFlappyRoyale is a competitive multiplayer version of the classic Flappy Bird, built fully on-chain using the METIS blockchain. In each match, 5 players stake a small amount of METIS (e.g., $0.1) to join. The player who survives the longest wins the pooled stake (e.g., $0.5), making every game a high-stakes, skill-based micro-competition. Users can also create custom lobbies with higher stakes, allowing players to define the value they want to play for.\nThe game rewards participation with an in-game token, Golden Eggs, earned after each round, which can be used to purchase cosmetic upgrades like bird skins, backgrounds, or pipe styles. This creates a sense of progression and personalization. All gameplay logic and staking/reward mechanisms are handled fully on-chain for transparency and fairness.\nCommunity Engagement Features\nTo onboard users and gamify the platform, we will implement:\nTestable Tasks\nComplete your first match\nWin a game\nCustomize your bird with in-game currency\nCreate a custom game lobby\nRefer a friend who plays a match\nStake METIS in a higher-tier match\nGolden Eggs ($EGGS) token system\n10 EGGS for a win\n15 EGGS for customizing your bird\n30 EGGS for referring a friend\nBonus 50 EGGS for joining a high-stakes match\nGamification\nUsers will earn points for each action, which can be displayed on a leaderboard and redeemed for cosmetic items or exclusive match access. This creates a sticky experience and encourages repeated engagement.\nOnboarding Incentive\nBy providing a progression system and visible rewards for participation, users are incentivized to try every feature and invite others, building a thriving and competitive community.\nGetting Involved\nRight now, we\u2019re looking for suggestions, feedback, and early supporters. If you\u2019re excited about FlappyRoyale, here\u2019s how you can contribute:\nShare ideas for game mechanics, skins, or in-game economy\nHelp shape the reward and staking system with your input\nProvide feedback as we build the first version\nOnce the game is ready, you\u2019ll be among the first to test, play, and compete. Early supporters may also receive exclusive cosmetics or perks for helping us get off the ground."
            },
            {
                "author": "priyankg3",
                "comment": "Hello\n@rafael-abuawad\n, Interesting Concept !\nJust want to know :-\nCan friends team up or spectate matches?\nWhat happens if two players tie by surviving the same amount of time?"
            },
            {
                "author": "han",
                "comment": "Thanks. FlappyRoyale sounds super fun and refreshingly innovative! Can I only use the $EGGS tokens for cosmetic items, or will they also have other use cases in the future (like special tournaments, NFTs, or staking)? Also, if my win rate increases significantly, could that create imbalance in the in-game economy?"
            },
            {
                "author": "rafael-abuawad",
                "comment": "hi\n@priyankg3\nwell, if that happens then we could be splitting prizes"
            },
            {
                "author": "rafael-abuawad",
                "comment": "@han\nfor now is only for cosmetics, thats the plan."
            },
            {
                "author": "CrisMetis",
                "comment": "As always as a fellow gamer, I can\u2019t don\u2019t like such an idea.I used to play Flappy Bird non-stop back in 2015, so the idea of a competitive, on-chain version with real rewards is super exciting."
            },
            {
                "author": "rafael-abuawad",
                "comment": "@CrisMetis\nI\u2019m hoping on having a playable demo soon, really soon! I will be sharing the links once its ready. I think that this is going to be different that most onchain games, since (most of the games that I played) are automatic, aka the player doesn\u2019t do anything, this is going to be more dynamic and fun, and I hope people like this"
            }
        ]
    },
    {
        "id": "17fd37427e7ca0ce",
        "topic_id": "6302",
        "title": "The ROI of Twitter Spaces, AMAs, and Community Calls",
        "url": "https://forum.ceg.vote/t/the-roi-of-twitter-spaces-amas-and-community-calls/6302",
        "views": "",
        "comments": "0",
        "created_date": "Jul 11, 2025 1:25 pm",
        "latest_activity": null,
        "content": "Let\u2019s talk about something many teams overlook when measuring ROI: real-time conversations.\nTwitter Spaces, AMAs, and community calls may not have the polish of a viral campaign or the analytics of a paid ad funnel, but they deliver something way more valuable\u2014trust.\nHere\u2019s how I\u2019ve seen these \u201clow-cost, high-context\u201d formats pay off in the long run:\n1. Direct Feedback = Product Gold\nHosting a casual AMA or open mic community call lets your users tell you exactly what they want\u2014without filling out a form or jumping through hoops. You\u2019ll hear pain points, feature requests, and even new use cases you never thought of. It\u2019s like live UX research, but faster and free.\n2. Stronger Community = Higher Retention\nPeople don\u2019t stick around just for good products\u2014they stay because they feel seen. Regular Spaces or calls build emotional connection. When users hear your voice or get their question answered live, it deepens loyalty. And loyal users are the best advocates.\n3. Thought Leadership = Organic Reach\nYou don\u2019t need to go viral. Just be consistent. Twitter Spaces and public AMAs give you a stage to share insights, not just updates. Over time, you become known as someone who shows up and knows what they\u2019re talking about. That builds authority\u2014and people start sharing your content organically.\n4. Collabs Happen in Real Time\nI\u2019ve seen unexpected partnerships form just because someone joined a community call or co-hosted a Space. These moments don\u2019t happen in emails or cold DMs\u2014they happen in public conversations where there\u2019s a shared vibe and momentum.\nSo what\u2019s the actual ROI?\nIf you\u2019re measuring success only in clicks or conversions, these formats might look soft. But if you\u2019re playing the long game\u2014building relationships, brand depth, and user insight\u2014they\u2019re a goldmine.\nMy tip: don\u2019t treat these calls as side content. Treat them as core infrastructure for your community strategy.\nWould love to know: Are you hosting regular live chats with your community? What\u2019s been the biggest surprise ROI for you?",
        "comments_details": [
            {
                "author": "Julie0xnana",
                "comment": "Let\u2019s talk about something many teams overlook when measuring ROI: real-time conversations.\nTwitter Spaces, AMAs, and community calls may not have the polish of a viral campaign or the analytics of a paid ad funnel, but they deliver something way more valuable\u2014trust.\nHere\u2019s how I\u2019ve seen these \u201clow-cost, high-context\u201d formats pay off in the long run:\n1. Direct Feedback = Product Gold\nHosting a casual AMA or open mic community call lets your users tell you exactly what they want\u2014without filling out a form or jumping through hoops. You\u2019ll hear pain points, feature requests, and even new use cases you never thought of. It\u2019s like live UX research, but faster and free.\n2. Stronger Community = Higher Retention\nPeople don\u2019t stick around just for good products\u2014they stay because they feel seen. Regular Spaces or calls build emotional connection. When users hear your voice or get their question answered live, it deepens loyalty. And loyal users are the best advocates.\n3. Thought Leadership = Organic Reach\nYou don\u2019t need to go viral. Just be consistent. Twitter Spaces and public AMAs give you a stage to share insights, not just updates. Over time, you become known as someone who shows up and knows what they\u2019re talking about. That builds authority\u2014and people start sharing your content organically.\n4. Collabs Happen in Real Time\nI\u2019ve seen unexpected partnerships form just because someone joined a community call or co-hosted a Space. These moments don\u2019t happen in emails or cold DMs\u2014they happen in public conversations where there\u2019s a shared vibe and momentum.\nSo what\u2019s the actual ROI?\nIf you\u2019re measuring success only in clicks or conversions, these formats might look soft. But if you\u2019re playing the long game\u2014building relationships, brand depth, and user insight\u2014they\u2019re a goldmine.\nMy tip: don\u2019t treat these calls as side content. Treat them as core infrastructure for your community strategy.\nWould love to know: Are you hosting regular live chats with your community? What\u2019s been the biggest surprise ROI for you?"
            }
        ]
    },
    {
        "id": "0da041bad09341e5",
        "topic_id": "6300",
        "title": "Redefining KOLs in the Age of Decentralized Social Media",
        "url": "https://forum.ceg.vote/t/redefining-kols-in-the-age-of-decentralized-social-media/6300",
        "views": "",
        "comments": "0",
        "created_date": "Jul 11, 2025 1:19 pm",
        "latest_activity": "Jul 11, 2025 1:19 pm",
        "content": "The role of Key Opinion Leaders (KOLs) is shifting\u2014and fast.\nIn the era of decentralized social media, where users control their data and algorithms no longer dictate reach, influence is no longer measured just by followers or likes. We\u2019re entering a phase where credibility and community ownership matter more than clout.\nTraditional KOLs built their empires on centralized platforms\u2014Instagram, YouTube, TikTok\u2014where algorithmic boosts and brand partnerships drove visibility. But as we move toward platforms like Farcaster, Lens, and others built on Web3 principles, the dynamics change:\nCommunity Over Audience\nIt\u2019s not just about broadcasting to passive followers anymore. Decentralized platforms reward creators who co-create with their communities. KOLs become community builders, not just content machines.\nOn-Chain Reputation\nIn Web3, your actions are transparent and verifiable. KOLs can\u2019t fake credibility. Did you support a project early? Did your advice lead to value creation? Your on-chain activity becomes your new resume.\nTokenized Influence\nSome creators are launching their own social tokens or DAOs, giving their communities a stake in their growth. Influence becomes a two-way street\u2014KOLs no longer \u201cown\u201d their audience; they share value with them.\nPlatform Independence\nDecentralized identity means your followers follow you, not just your handle on one platform. This breaks the dependency on any one algorithm or app. KOLs can now build durable influence that travels with them.\nSo what does this mean for marketers and creators?\nIt\u2019s time to stop thinking of KOLs as just \u201cinfluencers\u201d and start seeing them as community nodes. Look for those who aren\u2019t just loud but trusted. Who aren\u2019t just viral but verifiable. And who treat their audience not as consumers, but as collaborators.\nIn the decentralized era, KOLs aren\u2019t just amplifiers\u2014they\u2019re architects.\nWhat are you seeing in this space? Would love to hear how others are adapting.",
        "comments_details": [
            {
                "author": "Julie0xnana",
                "comment": "The role of Key Opinion Leaders (KOLs) is shifting\u2014and fast.\nIn the era of decentralized social media, where users control their data and algorithms no longer dictate reach, influence is no longer measured just by followers or likes. We\u2019re entering a phase where credibility and community ownership matter more than clout.\nTraditional KOLs built their empires on centralized platforms\u2014Instagram, YouTube, TikTok\u2014where algorithmic boosts and brand partnerships drove visibility. But as we move toward platforms like Farcaster, Lens, and others built on Web3 principles, the dynamics change:\nCommunity Over Audience\nIt\u2019s not just about broadcasting to passive followers anymore. Decentralized platforms reward creators who co-create with their communities. KOLs become community builders, not just content machines.\nOn-Chain Reputation\nIn Web3, your actions are transparent and verifiable. KOLs can\u2019t fake credibility. Did you support a project early? Did your advice lead to value creation? Your on-chain activity becomes your new resume.\nTokenized Influence\nSome creators are launching their own social tokens or DAOs, giving their communities a stake in their growth. Influence becomes a two-way street\u2014KOLs no longer \u201cown\u201d their audience; they share value with them.\nPlatform Independence\nDecentralized identity means your followers follow you, not just your handle on one platform. This breaks the dependency on any one algorithm or app. KOLs can now build durable influence that travels with them.\nSo what does this mean for marketers and creators?\nIt\u2019s time to stop thinking of KOLs as just \u201cinfluencers\u201d and start seeing them as community nodes. Look for those who aren\u2019t just loud but trusted. Who aren\u2019t just viral but verifiable. And who treat their audience not as consumers, but as collaborators.\nIn the decentralized era, KOLs aren\u2019t just amplifiers\u2014they\u2019re architects.\nWhat are you seeing in this space? Would love to hear how others are adapting."
            }
        ]
    },
    {
        "id": "02b34767ffcd1cf4",
        "topic_id": "6250",
        "title": "Zk-metis-sdk: Zero-Knowledge Made Simple for Metis",
        "url": "https://forum.ceg.vote/t/zk-metis-sdk-zero-knowledge-made-simple-for-metis/6250",
        "views": "",
        "comments": "5",
        "created_date": "Jul 9, 2025 6:45 am",
        "latest_activity": "Jul 11, 2025 12:46 pm",
        "content": "Project Name\nzk-metis-sdk \u2013 Zero-Knowledge Made Simple for Metis\nProblem Statement\nPrivacy-preserving applications are becoming critical in Web3, but working with zero-knowledge proofs remains complex and inaccessible for most developers. Tasks like generating zkSNARK proofs, integrating Solidity verifiers, and deploying to specific L2s such as Metis are highly technical and fragmented. As a result, developers building on Metis lack the tools to easily integrate zero-knowledge capabilities into their applications.\nSolution Overview\nzk-metis-sdk is a CLI and SDK toolkit that abstracts the full lifecycle of zero-knowledge proofs on the Metis Layer 2 network. It allows developers to compile Circom circuits, perform trusted setup (Groth16), generate proofs, and deploy Solidity verifier contracts directly to Metis. The SDK makes zk integration seamless for dApp developers, promoting privacy, verification, and attestation use cases across Metis-powered ecosystems like SocialFi, DeAI, and identity protocols.\nProject Description\nzk-metis-sdk is a developer-first, TypeScript-based CLI and SDK built to simplify the adoption of zero-knowledge proofs in the Metis ecosystem. Developers can write Circom circuits for logic such as age verification or anonymous attestation, and the SDK will handle:\nCompiling the circuit to .r1cs, .wasm, .zkey, and verifier.sol\nRunning Groth16 trusted setup using snarkjs\nGenerating proofs from input.json files\nDeploying Solidity verifier contracts directly to Metis (mainnet or testnet)\nVerifying zkSNARK proofs on-chain with minimal effort\nThe SDK is fully compatible with EVM tooling (Hardhat, Foundry, ethers.js) and will also expose a simple JavaScript API for integrating proof generation and on-chain verification in dApps.\nThis tool lowers the entry barrier for developers who want to build with privacy or verifiable computation in mind\u2014without diving deep into cryptography. We\u2019re excited by its potential to power next-gen apps in SocialFi, AI agents, KYC-less onboarding, and private DAOs on Metis.\nCommunity Engagement Features\nTo onboard users and gamify zk development, we\u2019ll provide a playground and points-based rewards:\nTestable Features/Tasks\nGenerate and verify a proof using a sample circuit\nDeploy a verifier contract on Metis Sepolia\nBuild a zk-based demo (e.g., private voting, anonymous credential check)\nShare a new zk circuit with the community\nPoints System\n+20 points: Complete local proof generation\n+50 points: Deploy a verifier to Metis\n+30 points: Share a public zk use case on the forum\n+100 points: Submit a working dApp built using zk-metis-sdk\nGamification\nLeaderboard of zk builders within the community\nExclusive zk contributor NFTs and badges\nFeature top users in community showcases\nEarly contributor rewards and possible grant nomination from Metis\nThis encourages active learning, open experimentation, and repeat usage among developers while building traction for zk tooling within Metis.\nGetting Involved\nInterested contributors can:\nJoin the GitHub repo to contribute to Circom templates, Solidity verifiers, or CLI improvements\nShare zk use cases, feedback, or bug reports via our community thread\nUse the SDK and post tutorials, demos, or improvements\nCollaborate with us to build integrations into Metis-powered platforms (e.g., SocialFi, AI, DePIN)\nWhether you\u2019re a Solidity dev, zk researcher, or AI enthusiast, you can help shape the future of privacy-preserving dApps on Metis by building with and contributing to zk-metis-sdk.",
        "comments_details": [
            {
                "author": "jatinsahijwani",
                "comment": "Project Name\nzk-metis-sdk \u2013 Zero-Knowledge Made Simple for Metis\nProblem Statement\nPrivacy-preserving applications are becoming critical in Web3, but working with zero-knowledge proofs remains complex and inaccessible for most developers. Tasks like generating zkSNARK proofs, integrating Solidity verifiers, and deploying to specific L2s such as Metis are highly technical and fragmented. As a result, developers building on Metis lack the tools to easily integrate zero-knowledge capabilities into their applications.\nSolution Overview\nzk-metis-sdk is a CLI and SDK toolkit that abstracts the full lifecycle of zero-knowledge proofs on the Metis Layer 2 network. It allows developers to compile Circom circuits, perform trusted setup (Groth16), generate proofs, and deploy Solidity verifier contracts directly to Metis. The SDK makes zk integration seamless for dApp developers, promoting privacy, verification, and attestation use cases across Metis-powered ecosystems like SocialFi, DeAI, and identity protocols.\nProject Description\nzk-metis-sdk is a developer-first, TypeScript-based CLI and SDK built to simplify the adoption of zero-knowledge proofs in the Metis ecosystem. Developers can write Circom circuits for logic such as age verification or anonymous attestation, and the SDK will handle:\nCompiling the circuit to .r1cs, .wasm, .zkey, and verifier.sol\nRunning Groth16 trusted setup using snarkjs\nGenerating proofs from input.json files\nDeploying Solidity verifier contracts directly to Metis (mainnet or testnet)\nVerifying zkSNARK proofs on-chain with minimal effort\nThe SDK is fully compatible with EVM tooling (Hardhat, Foundry, ethers.js) and will also expose a simple JavaScript API for integrating proof generation and on-chain verification in dApps.\nThis tool lowers the entry barrier for developers who want to build with privacy or verifiable computation in mind\u2014without diving deep into cryptography. We\u2019re excited by its potential to power next-gen apps in SocialFi, AI agents, KYC-less onboarding, and private DAOs on Metis.\nCommunity Engagement Features\nTo onboard users and gamify zk development, we\u2019ll provide a playground and points-based rewards:\nTestable Features/Tasks\nGenerate and verify a proof using a sample circuit\nDeploy a verifier contract on Metis Sepolia\nBuild a zk-based demo (e.g., private voting, anonymous credential check)\nShare a new zk circuit with the community\nPoints System\n+20 points: Complete local proof generation\n+50 points: Deploy a verifier to Metis\n+30 points: Share a public zk use case on the forum\n+100 points: Submit a working dApp built using zk-metis-sdk\nGamification\nLeaderboard of zk builders within the community\nExclusive zk contributor NFTs and badges\nFeature top users in community showcases\nEarly contributor rewards and possible grant nomination from Metis\nThis encourages active learning, open experimentation, and repeat usage among developers while building traction for zk tooling within Metis.\nGetting Involved\nInterested contributors can:\nJoin the GitHub repo to contribute to Circom templates, Solidity verifiers, or CLI improvements\nShare zk use cases, feedback, or bug reports via our community thread\nUse the SDK and post tutorials, demos, or improvements\nCollaborate with us to build integrations into Metis-powered platforms (e.g., SocialFi, AI, DePIN)\nWhether you\u2019re a Solidity dev, zk researcher, or AI enthusiast, you can help shape the future of privacy-preserving dApps on Metis by building with and contributing to zk-metis-sdk."
            },
            {
                "author": "han",
                "comment": "Will the SDK support other zk proving systems in the future, such as PlonK or Halo2?"
            },
            {
                "author": "daryl",
                "comment": "@LazAI_Helper_bot\nwhat specific LazAI functionality might help for the above project?"
            },
            {
                "author": "LazAI_Helper_bot",
                "comment": "Okay, I\u2019ve reviewed the discussion about the zk-metis-sdk project. Given its goals and the question posed by Han, here\u2019s how LazAI functionality could potentially assist:\nLLM Client for Circom Circuit Generation/Optimization:\nLazAI\u2019s llm_client could be used to create an AI-powered assistant that helps developers write Circom circuits. The LLM could:\nSuggest optimal circuit designs based on the desired functionality.\nIdentify potential vulnerabilities or inefficiencies in existing circuits.\nAutomatically generate boilerplate code for common ZK patterns.\nThis addresses the \u201ccomplex and inaccessible\u201d nature of ZK proof development.\nAlith Agent for Automated Verifier Deployment and Testing:\nAn Alith agent could be built to automate the deployment and testing of Solidity verifier contracts on Metis.\nThis agent could:\nMonitor the Metis network for successful deployments.\nRun automated tests to verify the correctness of the verifier contract.\nReport any errors or anomalies to the developer.\nThis streamlines the deployment process and ensures the reliability of ZK integrations.\nLazChain Integration for Decentralized ZK Proof Verification (Future):\nIn the future, LazAI could leverage LazChain to create a decentralized ZK proof verification system.\nThis would allow verifiers to be deployed and executed in a trustless manner, enhancing the security and transparency of ZK-based applications.\nThis aligns with the broader goal of decentralized AI and Web3 integration.\nModel Context Protocol (MCP) for managing Zero Knowledge templates and use cases\nThe MCP could be employed to create a standardized library of zero-knowledge templates and use cases. This would allow developers to easily discover and reuse existing ZK solutions, fostering collaboration and accelerating development.\nIn response to Han\u2019s question about PlonK/Halo2 support, the Alith agent could be used to benchmark the performance of different proving systems on Metis and recommend the most efficient option for a given application."
            },
            {
                "author": "jatinsahijwani",
                "comment": "Hi Han, thanks for the great question!\nAt the current stage, zk-metis-sdk is focused on supporting Groth16 via Circom and SnarkJS, since it\u2019s the most widely adopted and production-ready proving system compatible with Solidity verifiers. This ensures that developers can deploy zero-knowledge verification logic on Metis quickly with minimal complexity.\nThat said, we absolutely plan to extend support to other proving systems such as PlonK and eventually Halo2, especially as Solidity-compatible verifiers become more efficient and tools like zkInterface and Halo2-solidity mature.\nFuture roadmap goals include:\nIntegrating snarkjs plonk pipelines for projects requiring faster setup times.\nExploring native support for Halo2 and pluggable backends like arkworks and halo2lib.\nProviding a unified interface within the SDK, so developers can choose the proving system based on their use case (e.g., trusted setup vs universal setup, proof size, verifier cost).\nWe\u2019re also exploring how benchmarking agents (like what LazAI suggested) could help recommend the best proving system dynamically.\nReally appreciate the input \u2014 this kind of feedback helps guide our roadmap!"
            },
            {
                "author": "jatinsahijwani",
                "comment": "Thanks for the help."
            }
        ]
    },
    {
        "id": "cb380610018755c6",
        "topic_id": "4778",
        "title": "Not a Dev, Still Building",
        "url": "https://forum.ceg.vote/t/not-a-dev-still-building/4778",
        "views": "",
        "comments": "7",
        "created_date": "May 26, 2025 9:05 am",
        "latest_activity": "Jul 11, 2025 11:36 am",
        "content": "GM GM frens!\nJust wanted to drop a quick intro as I settle into the forum. I\u2019m someone who kinda stumbled into Web3 out of curiosity \u2014 and never left. You know how it goes: one minute you\u2019re reading about Ethereum, next thing you know you\u2019re deep in governance proposals, DeFi rabbit holes, and memecoins with questionable logos\nI\u2019m not a dev or founder (yet), but I\u2019m here to learn, create, and contribute in any way I can. I\u2019m especially into breaking down complex stuff \u2014 whether it\u2019s DeFi, L2 scaling, or DAOs \u2014 and making it more approachable for others. I believe the more people actually understand this space, the stronger we all get.\nWhether it\u2019s writing threads, making memes, or just asking the \u201cdumb\u201d questions (which are often the best ones), I\u2019m here for the long game.\nIf you\u2019re building, exploring, or just trying to figure things out like me \u2014 let\u2019s connect. Web3\u2019s better when we build together.\nExcited to be here and grow with y\u2019all",
        "comments_details": [
            {
                "author": "Evelyn",
                "comment": "GM GM frens!\nJust wanted to drop a quick intro as I settle into the forum. I\u2019m someone who kinda stumbled into Web3 out of curiosity \u2014 and never left. You know how it goes: one minute you\u2019re reading about Ethereum, next thing you know you\u2019re deep in governance proposals, DeFi rabbit holes, and memecoins with questionable logos\nI\u2019m not a dev or founder (yet), but I\u2019m here to learn, create, and contribute in any way I can. I\u2019m especially into breaking down complex stuff \u2014 whether it\u2019s DeFi, L2 scaling, or DAOs \u2014 and making it more approachable for others. I believe the more people actually understand this space, the stronger we all get.\nWhether it\u2019s writing threads, making memes, or just asking the \u201cdumb\u201d questions (which are often the best ones), I\u2019m here for the long game.\nIf you\u2019re building, exploring, or just trying to figure things out like me \u2014 let\u2019s connect. Web3\u2019s better when we build together.\nExcited to be here and grow with y\u2019all"
            },
            {
                "author": "Julie0xnana",
                "comment": "Welcome to the Metis Forum, Evelyn!"
            },
            {
                "author": "Liametis",
                "comment": "gm gm welcome to the Metisian squad Evelyn\ni started out cryptocurious just like as you and now im a full time addict lol"
            },
            {
                "author": "priyankg3",
                "comment": "Welcome Evelyn to the Metis Forum"
            },
            {
                "author": "han",
                "comment": "GM! Love the energy- totally relate to the \u201cfell in and never left\u201d vibe."
            },
            {
                "author": "4ngel",
                "comment": "Welcome to the Metis family"
            },
            {
                "author": "Gigabriansmith",
                "comment": "lol that was me too"
            },
            {
                "author": "CrisMetis",
                "comment": "That\u2019s kind of many people story in web3 lol"
            }
        ]
    },
    {
        "id": "9e9a09f462f46ee5",
        "topic_id": "6261",
        "title": "Building Products That Endure Slumps: Consistency Over Motivation",
        "url": "https://forum.ceg.vote/t/building-products-that-endure-slumps-consistency-over-motivation/6261",
        "views": "",
        "comments": "2",
        "created_date": "Jul 9, 2025 2:14 pm",
        "latest_activity": "Jul 11, 2025 10:50 am",
        "content": "Consistency is the key\nIn bull markets, it\u2019s easy to feel like your product matters. There\u2019s hype, noise, people engaging. But when things slow down, you realise if you were building for attention or for real utility.\nI\u2019ve seen this across a few cycles now. Projects that last aren\u2019t powered by motivation. They\u2019re built on discipline. When energy is low, consistency is the edge. As seen in the Bear markets don\u2019t kill builders. They expose the ones who were only tweeting\ud83d\udd25\nA few things that help:\n\u2022 keep showing up even when it feels pointless\n\u2022 talk to users even if it\u2019s just one person a week\n\u2022 ship something small often\n\u2022 track your own progress not the market\n\u2022 share updates no matter the size\nHow are you staying consistent right now. Any routines or systems that help when motivation drops\nDrop them below, might help someone else building in silence too",
        "comments_details": [
            {
                "author": "Norbert",
                "comment": "Consistency is the key\nIn bull markets, it\u2019s easy to feel like your product matters. There\u2019s hype, noise, people engaging. But when things slow down, you realise if you were building for attention or for real utility.\nI\u2019ve seen this across a few cycles now. Projects that last aren\u2019t powered by motivation. They\u2019re built on discipline. When energy is low, consistency is the edge. As seen in the Bear markets don\u2019t kill builders. They expose the ones who were only tweeting\ud83d\udd25\nA few things that help:\n\u2022 keep showing up even when it feels pointless\n\u2022 talk to users even if it\u2019s just one person a week\n\u2022 ship something small often\n\u2022 track your own progress not the market\n\u2022 share updates no matter the size\nHow are you staying consistent right now. Any routines or systems that help when motivation drops\nDrop them below, might help someone else building in silence too"
            },
            {
                "author": "Gann",
                "comment": "Consistency is so underrated\nIt\u2019s not flashy, it doesn\u2019t go viral, but it quietly compounds.\nWe are in that phase now"
            },
            {
                "author": "CrisMetis",
                "comment": "Love this post! Consistency really is everything."
            }
        ]
    },
    {
        "id": "2368fe279492e2f4",
        "topic_id": "6176",
        "title": "Email Marketing in Crypto: What\u2019s Legal, What Actually Works",
        "url": "https://forum.ceg.vote/t/email-marketing-in-crypto-what-s-legal-what-actually-works/6176",
        "views": "",
        "comments": "2",
        "created_date": "Jul 7, 2025 3:59 pm",
        "latest_activity": "Jul 11, 2025 10:47 am",
        "content": "Email might feel old-school in the fast-moving world of crypto, but it\u2019s still one of the most effective ways to reach your community \u2014 if you do it right.\nSo let\u2019s talk about what you can legally do, and what actually works when it comes to email marketing in Web3.\nFirst Things First: What\u2019s Legal?\nEven though we\u2019re in crypto, email still plays by Web2 rules. Here\u2019s the quick version:\nDon\u2019t buy email lists \u2013 ever.\nAlways get permission (especially if your audience is in the EU \u2013 hello GDPR).\nInclude an easy unsubscribe link, use a real sender name, and don\u2019t do clickbait subject lines (CAN-SPAM rules in the US).\nDouble opt-in is your safest bet for staying compliant everywhere.\nTL;DR: Just be transparent, respectful, and don\u2019t spam people.\nWhat Works in Crypto Email Marketing?\nHere\u2019s what tends to get good results:\nEducational content: Simple explainers, staking how-tos, project updates.\nWeekly community updates: Think of it like your \u201cin case you missed it\u201d digest.\nLaunch alerts: Airdrops, IDOs, whitelist reminders \u2014 people want to know!\nPersonalization: Builders don\u2019t need the same emails as NFT collectors. Segment where you can.\nKeep it clean, keep it simple, and don\u2019t overload with info.\nTools You Can Use\nSome platforms are more crypto-friendly than others. Here are a few:\nBrevo (Sendinblue) \u2013 solid for automation and wallet segmentation.\nMailerLite / EmailOctopus / Klaviyo \u2013 good flexibility.\nMailchimp \u2013 works\u2026 until it doesn\u2019t. They\u2019re strict with crypto projects.\nIf you\u2019re starting fresh, warm up your domain slowly to avoid spam filters.\nFinal Thoughts\nEmail is still underrated in crypto. It builds trust, keeps your community informed, and gives you direct access to your audience, no algorithm in the way.\nJust make sure you\u2019re playing by the rules and sending stuff people actually want to read.",
        "comments_details": [
            {
                "author": "Rosita",
                "comment": "Email might feel old-school in the fast-moving world of crypto, but it\u2019s still one of the most effective ways to reach your community \u2014 if you do it right.\nSo let\u2019s talk about what you can legally do, and what actually works when it comes to email marketing in Web3.\nFirst Things First: What\u2019s Legal?\nEven though we\u2019re in crypto, email still plays by Web2 rules. Here\u2019s the quick version:\nDon\u2019t buy email lists \u2013 ever.\nAlways get permission (especially if your audience is in the EU \u2013 hello GDPR).\nInclude an easy unsubscribe link, use a real sender name, and don\u2019t do clickbait subject lines (CAN-SPAM rules in the US).\nDouble opt-in is your safest bet for staying compliant everywhere.\nTL;DR: Just be transparent, respectful, and don\u2019t spam people.\nWhat Works in Crypto Email Marketing?\nHere\u2019s what tends to get good results:\nEducational content: Simple explainers, staking how-tos, project updates.\nWeekly community updates: Think of it like your \u201cin case you missed it\u201d digest.\nLaunch alerts: Airdrops, IDOs, whitelist reminders \u2014 people want to know!\nPersonalization: Builders don\u2019t need the same emails as NFT collectors. Segment where you can.\nKeep it clean, keep it simple, and don\u2019t overload with info.\nTools You Can Use\nSome platforms are more crypto-friendly than others. Here are a few:\nBrevo (Sendinblue) \u2013 solid for automation and wallet segmentation.\nMailerLite / EmailOctopus / Klaviyo \u2013 good flexibility.\nMailchimp \u2013 works\u2026 until it doesn\u2019t. They\u2019re strict with crypto projects.\nIf you\u2019re starting fresh, warm up your domain slowly to avoid spam filters.\nFinal Thoughts\nEmail is still underrated in crypto. It builds trust, keeps your community informed, and gives you direct access to your audience, no algorithm in the way.\nJust make sure you\u2019re playing by the rules and sending stuff people actually want to read."
            },
            {
                "author": "David",
                "comment": "Great breakdown, email\u2019s still a powerful channel when used right. Curious, have you found any tools that handle wallet-based segmentation really well?"
            },
            {
                "author": "CrisMetis",
                "comment": "This is a great content, precise and clear, I do agree on the fact the email and newsletters have still a high-retention rate, however it is definitely underrated and not widely used in web3, most likely cause recently the whole industry is going through short/hype posts done by KOLs on platforms such X, which are not always quality ones."
            }
        ]
    },
    {
        "id": "238db74d834e05f1",
        "topic_id": "6003",
        "title": "How AI is Transforming Day-to-Day Operation (And Making Operators Life Easier)",
        "url": "https://forum.ceg.vote/t/how-ai-is-transforming-day-to-day-operation-and-making-operators-life-easier/6003",
        "views": "",
        "comments": "2",
        "created_date": "Jun 27, 2025 9:09 am",
        "latest_activity": "Jul 11, 2025 10:32 am",
        "content": "AI isn\u2019t just a cool word anymore or some kind of robots that we saw in cool old movies like Matrix, Terminator and so on, it\u2019s right now truly changing how we work and coming into our daily work not only on the MKT side but also and especially for people in operations.\nThink about all those repetitive and tedious tasks, like entering specific data, scheduling calls, or keeping track of your backlog and many others. More and more companies are turning to AI tools to automate these jobs and free up precious time to some guy in the company.\nI\u2019m talking about you, the operators. You\u2019re the people who keep projects on track, make sure everyone knows what they\u2019re doing, and help teams actually get things done. You\u2019re the ones holding it all together behind the scenes. And in Web3, that\u2019s no small task.\nThink about your day-to-day. You\u2019re juggling timelines, coordinating devs and designers, checking community sentiment, keeping stakeholders updated, chasing people for approvals, monitoring governance proposals, handling compliance checks, and making sure a dozen moving parts don\u2019t crash into each other.\nIt\u2019s a LOT. And let\u2019s be realistic, some of it\u2019s very annoying, and you might be thinking why me ???\nLike manually updating dashboards with the latest on-chain data, tracking smart contract deployments across multiple chains, prepping endless reports, or combing through Discord for community feedback.\nHere\u2019s where AI comes in to make life easier:\nImagine AI tools that auto-summarize long governance threads so you\u2019re not reading walls of text. Or AI agents that pull real-time blockchain analytics straight into your dashboards without you lifting a finger. Or bots that sift through Discord and Telegram to highlight emerging issues or common user questions before they blow up.\nAI is also stepping up in risk and security ops. Tools out there are ready for scanning chains for suspicious activity 24/7, flagging potential exploits before they become PR nightmares. For operators, that\u2019s huge peace of mind, and fewer fires to fight at 2 a.m.\nEven the boring parts of scheduling and planning are getting smoother. AI can help coordinate multi-sig signers in different time zones, manage task boards, or generate project updates for stakeholders. Less copy-pasting, more time spent on real problem-solving.\nAnd here\u2019s the thing that must be mentioned: AI\u2019s not replacing operator. it\u2019s freeing them up. It handles the repetitive grind so we can focus on strategic decisions, creative solutions, and keeping our projects moving forward.\nSo if you\u2019re in Web3 ops, the question isn\u2019t whether AI will affect your work, it\u2019s how you\u2019ll harness it to make your job easier and your projects even more successful.\nSo fellas, how do you see AI helping you stay on top of your operations game?",
        "comments_details": [
            {
                "author": "CrisMetis",
                "comment": "AI isn\u2019t just a cool word anymore or some kind of robots that we saw in cool old movies like Matrix, Terminator and so on, it\u2019s right now truly changing how we work and coming into our daily work not only on the MKT side but also and especially for people in operations.\nThink about all those repetitive and tedious tasks, like entering specific data, scheduling calls, or keeping track of your backlog and many others. More and more companies are turning to AI tools to automate these jobs and free up precious time to some guy in the company.\nI\u2019m talking about you, the operators. You\u2019re the people who keep projects on track, make sure everyone knows what they\u2019re doing, and help teams actually get things done. You\u2019re the ones holding it all together behind the scenes. And in Web3, that\u2019s no small task.\nThink about your day-to-day. You\u2019re juggling timelines, coordinating devs and designers, checking community sentiment, keeping stakeholders updated, chasing people for approvals, monitoring governance proposals, handling compliance checks, and making sure a dozen moving parts don\u2019t crash into each other.\nIt\u2019s a LOT. And let\u2019s be realistic, some of it\u2019s very annoying, and you might be thinking why me ???\nLike manually updating dashboards with the latest on-chain data, tracking smart contract deployments across multiple chains, prepping endless reports, or combing through Discord for community feedback.\nHere\u2019s where AI comes in to make life easier:\nImagine AI tools that auto-summarize long governance threads so you\u2019re not reading walls of text. Or AI agents that pull real-time blockchain analytics straight into your dashboards without you lifting a finger. Or bots that sift through Discord and Telegram to highlight emerging issues or common user questions before they blow up.\nAI is also stepping up in risk and security ops. Tools out there are ready for scanning chains for suspicious activity 24/7, flagging potential exploits before they become PR nightmares. For operators, that\u2019s huge peace of mind, and fewer fires to fight at 2 a.m.\nEven the boring parts of scheduling and planning are getting smoother. AI can help coordinate multi-sig signers in different time zones, manage task boards, or generate project updates for stakeholders. Less copy-pasting, more time spent on real problem-solving.\nAnd here\u2019s the thing that must be mentioned: AI\u2019s not replacing operator. it\u2019s freeing them up. It handles the repetitive grind so we can focus on strategic decisions, creative solutions, and keeping our projects moving forward.\nSo if you\u2019re in Web3 ops, the question isn\u2019t whether AI will affect your work, it\u2019s how you\u2019ll harness it to make your job easier and your projects even more successful.\nSo fellas, how do you see AI helping you stay on top of your operations game?"
            },
            {
                "author": "irinaina",
                "comment": "Awesome summary of how AI is transforming operations, and a great question.\nI believe nothing will ever replace genuine, authentic human judgment when it comes to organizing a project\u2019s work. But AI is an incredibly powerful tool that makes our work more efficient, faster, and easier. For me, it\u2019s a huge time-saver and an always-available assistant, even when a crazy idea pops into my head in the middle of the night, I can instantly ask AI whether it\u2019s feasible.\nNothing can replace human-to-human interaction, with all the empathy and nuance it brings. But embracing AI as a tool to support your work can make your job smoother and a lot more enjoyable.\nAs I mentioned, one of the ways I use AI in my workflow is by sharing all possible information about the project and regularly discussing new features, updates, and any issues that arise. Over time, as it learns this context, AI becomes an even better and more effective assistant. In a way, we learn from each other."
            },
            {
                "author": "CrisMetis",
                "comment": "Thank you so much Irinaina, yes exactly, different words but same take, AI isn\u2019t going to replace us but helping in workflow and endless tasks or daily operations. Oh, and of course it the human-to-human interaction, must be protected."
            }
        ]
    },
    {
        "id": "52de8e31eba960ad",
        "topic_id": "5206",
        "title": "Request DEX Test Tokens Here",
        "url": "https://forum.ceg.vote/t/request-dex-test-tokens-here/5206",
        "views": "",
        "comments": "14",
        "created_date": "Jun 3, 2025 6:32 pm",
        "latest_activity": "Jul 11, 2025 9:08 am",
        "content": "Hi Everyone, we launched the Hype Test DEX. If you need test tokens, please drop your wallet and I\u2019ll send some to you.\nhype-test-dex.metis.io\nHype Test DEX\nHype Test DEX\nMore information about dev resources, including the subgraph for this DEX can be found here:\nMetis Docs\nTest DEX | Metis Docs\nLearn how to use the Test DEX and its subgraph\nI will send Test USDT (0x3c099E287eC71b4AA61A7110287D715389329237) to your address",
        "comments_details": [
            {
                "author": "pavel",
                "comment": "Hi Everyone, we launched the Hype Test DEX. If you need test tokens, please drop your wallet and I\u2019ll send some to you.\nhype-test-dex.metis.io\nHype Test DEX\nHype Test DEX\nMore information about dev resources, including the subgraph for this DEX can be found here:\nMetis Docs\nTest DEX | Metis Docs\nLearn how to use the Test DEX and its subgraph\nI will send Test USDT (0x3c099E287eC71b4AA61A7110287D715389329237) to your address"
            },
            {
                "author": "t9fiction",
                "comment": "0x8ef123b0bCC118e522Fd202d11d691b88F38F312"
            },
            {
                "author": "priyankg3",
                "comment": "Sending now\n0x1da949F6e892FC88184645cf46522AABC0510cFd"
            },
            {
                "author": "4ngel",
                "comment": "0x30ddc7b142d23c57ec2764cd4d28c5ca2338d260\nCan\u2019t wait to test thanks"
            },
            {
                "author": "spxctr00m",
                "comment": "0x3f79824989897Fb20b24ee4373041dE5dc9885eE\nThanks"
            },
            {
                "author": "abhiraj2404",
                "comment": "0x88beE8eb691FFAFB192BAC4D1E7042e1b44c3eF2"
            },
            {
                "author": "huudangdx",
                "comment": "0x583B5b69416a53dEdfd45c6c3486c40fce70dED6"
            },
            {
                "author": "yano",
                "comment": "0x7d5E9Fc2D79ed404fbfDe64f93b199cFCC1bB3c1"
            },
            {
                "author": "trungkien1992",
                "comment": "0xED217008de92D861b6990381abc9c6C27822B34A\nThank you ser."
            },
            {
                "author": "touhonoob",
                "comment": "0xde65B8A93BC23c4b4186868014759632F2D288Ef"
            },
            {
                "author": "aeither",
                "comment": "0xa830cd34d83c10ba3a8bb2f25ff8bbae9bcd0125"
            },
            {
                "author": "JustineDevs",
                "comment": "0x44604bb3A940E93E644ae03A96b876dF1417F750"
            },
            {
                "author": "xav1er",
                "comment": "0x6Abad737Cfe0dA9DD4B9586d29CeeFB15e07515d"
            },
            {
                "author": "JustineDevs",
                "comment": "0xa43B752B6E941263eb5A7E3b96e2e0DEA1a586Ff"
            }
        ]
    },
    {
        "id": "18a1957417fd1ffc",
        "topic_id": "6284",
        "title": "MortalCoin: Trading Simulation Fighting Game \u2013 Outtrade Your Opponent to Win",
        "url": "https://forum.ceg.vote/t/mortalcoin-trading-simulation-fighting-game-outtrade-your-opponent-to-win/6284",
        "views": "",
        "comments": "2",
        "created_date": "Jul 10, 2025 7:36 pm",
        "latest_activity": "Jul 11, 2025 9:01 am",
        "content": "Project Name\nMortalCoin: Trading Simulation Fighting Game \u2013 Outtrade Your Opponent to Win\nProblem Statement\nThe Web3 space thrives on trading, competition, and game-like experiences - yet these elements remain largely disconnected. Trading is typically solitary and chart-driven, while gaming and meme culture live in separate silos.\nWe see an opportunity to unify these dimensions into a real-time, skill-based PvP/PvE battleground - where cryptocurrencies come to life as unique, playable characters.\nInspired by the speed of Hyperliquid, the strategic depth of poker, and the intensity of Mortal Kombat, our game turns speculative trading into an engaging, competitive, and entertaining experience.\nSolution Overview\nMortalCoin transforms crypto trading into a real-time combat game, where players \u201cfight\u201d by outperforming their opponents in simulated market environments using real price feeds. Each cryptocurrency is represented as a unique character, adding personality and emotional attachment to assets.\nDuring the hackathon, we plan to make significant progress on three key fronts:\nContinue the transition from a MVP Telegram Mini App to a full-featured Web App.\nFinalize the alpha release of our core PvP and PvE trading game modes, ensuring smooth real-time gameplay.\nContinue on-chain R&D and deploy our first on-chain logic using Metis\u2019s Hyperion, laying the foundation for trustless game mechanics where key gameplay elements can be cryptographically verified.\nOur broader goal is to demonstrate that a fast-paced trading game can operate with minimal latency while preserving the transparency, integrity, and verifiability of Web3 systems.\nOur uniqueness lies in blending real-time trading simulation with PvP battle mechanics and on-chain adjudication (TBD) - framed as a meme-powered arena where crypto assets are reimagined as animated, playable characters.\nProject Description\nMortalCoin is a real-time PvP/PvE crypto trading game where players battle using simulated trades based on live market data. Think Mortal Kombat meets Hyperliquid, with cryptocurrencies personified as unique, playable fighters. Each battle simulates a short trading session where players choose strategies and try to outtrade their opponents.\nThe simplified gameplay MVP has already launched as a Telegram Mini App (Season 1 started June 1st): @themortalcoin_bot, with around 10000 users played so far. We\u2019re now expanding to web, integrating EVM functionality.\nWebsite: https://mortalcoin.app\nHyperhack Hackathon web version build (wip - you can fight an AFK ghost for now, just click \u201cStart Fight\u201d): https://stage.mortalcoin.app\nGameplay teaser: https://www.youtube.com/shorts/04vbwJzEBio\nWhitepaper draft: https://docs.mortalcoin.app\nDeck draft: https://www.canva.com/design/DAGsSaY6o4g/jE94ckGrT4ahyOBNykFpFw/edit\nCommunity Engagement Features\nWe have several features designed to drive virality and user engagement:\nLeaderboards \u2013 We tested time-limited, incentivized leaderboards in the Telegram Mini App, attracting nearly 4,000 players in June. This will be brought to the web version.\nReferral System \u2013 Already live in Telegram and planned for the web version.\nMissions \u2013 Tasks like \u201cWin X fights,\u201d \u201cWin with a specific coin,\u201d \u201cRefer a friend,\u201d and daily/weekly challenges will carry over to web.\nDaily Free Tickets \u2013 Players get free tickets (needed for battles) daily, boosting retention and routine engagement.\nWe use an internal soft currency called tickets, required to play PvP and PvE battles. Tickets can be earned through missions, referrals, daily claims, or purchases, forming the foundation of our progression system.\nPlayers also earn MortalPoints (MP) by winning fights and completing challenges. MP reflects player skill and activity, and will later be spendable in the in-game store or used in token/NFT-based incentives like tournaments or airdrops.\nLooking ahead, we also plan to introduce an ELO rating system with ranked divisions\u2014adding a competitive layer that rewards performance and progression over time.\nGetting Involved\nEveryone is welcome to join our Telegram chat: Telegram: View @mortalcoin_chat and share suggestions or ideas.\nRight now, we\u2019re in the middle of transitioning our backend from Telegram Mini App support to a full web experience. We anticipate a playable web version with engaging gameplay and on-chain mechanics to be ready by the end of July - and we\u2019ll need plenty of help testing and playing!",
        "comments_details": [
            {
                "author": "tonymorony",
                "comment": "Project Name\nMortalCoin: Trading Simulation Fighting Game \u2013 Outtrade Your Opponent to Win\nProblem Statement\nThe Web3 space thrives on trading, competition, and game-like experiences - yet these elements remain largely disconnected. Trading is typically solitary and chart-driven, while gaming and meme culture live in separate silos.\nWe see an opportunity to unify these dimensions into a real-time, skill-based PvP/PvE battleground - where cryptocurrencies come to life as unique, playable characters.\nInspired by the speed of Hyperliquid, the strategic depth of poker, and the intensity of Mortal Kombat, our game turns speculative trading into an engaging, competitive, and entertaining experience.\nSolution Overview\nMortalCoin transforms crypto trading into a real-time combat game, where players \u201cfight\u201d by outperforming their opponents in simulated market environments using real price feeds. Each cryptocurrency is represented as a unique character, adding personality and emotional attachment to assets.\nDuring the hackathon, we plan to make significant progress on three key fronts:\nContinue the transition from a MVP Telegram Mini App to a full-featured Web App.\nFinalize the alpha release of our core PvP and PvE trading game modes, ensuring smooth real-time gameplay.\nContinue on-chain R&D and deploy our first on-chain logic using Metis\u2019s Hyperion, laying the foundation for trustless game mechanics where key gameplay elements can be cryptographically verified.\nOur broader goal is to demonstrate that a fast-paced trading game can operate with minimal latency while preserving the transparency, integrity, and verifiability of Web3 systems.\nOur uniqueness lies in blending real-time trading simulation with PvP battle mechanics and on-chain adjudication (TBD) - framed as a meme-powered arena where crypto assets are reimagined as animated, playable characters.\nProject Description\nMortalCoin is a real-time PvP/PvE crypto trading game where players battle using simulated trades based on live market data. Think Mortal Kombat meets Hyperliquid, with cryptocurrencies personified as unique, playable fighters. Each battle simulates a short trading session where players choose strategies and try to outtrade their opponents.\nThe simplified gameplay MVP has already launched as a Telegram Mini App (Season 1 started June 1st): @themortalcoin_bot, with around 10000 users played so far. We\u2019re now expanding to web, integrating EVM functionality.\nWebsite: https://mortalcoin.app\nHyperhack Hackathon web version build (wip - you can fight an AFK ghost for now, just click \u201cStart Fight\u201d): https://stage.mortalcoin.app\nGameplay teaser: https://www.youtube.com/shorts/04vbwJzEBio\nWhitepaper draft: https://docs.mortalcoin.app\nDeck draft: https://www.canva.com/design/DAGsSaY6o4g/jE94ckGrT4ahyOBNykFpFw/edit\nCommunity Engagement Features\nWe have several features designed to drive virality and user engagement:\nLeaderboards \u2013 We tested time-limited, incentivized leaderboards in the Telegram Mini App, attracting nearly 4,000 players in June. This will be brought to the web version.\nReferral System \u2013 Already live in Telegram and planned for the web version.\nMissions \u2013 Tasks like \u201cWin X fights,\u201d \u201cWin with a specific coin,\u201d \u201cRefer a friend,\u201d and daily/weekly challenges will carry over to web.\nDaily Free Tickets \u2013 Players get free tickets (needed for battles) daily, boosting retention and routine engagement.\nWe use an internal soft currency called tickets, required to play PvP and PvE battles. Tickets can be earned through missions, referrals, daily claims, or purchases, forming the foundation of our progression system.\nPlayers also earn MortalPoints (MP) by winning fights and completing challenges. MP reflects player skill and activity, and will later be spendable in the in-game store or used in token/NFT-based incentives like tournaments or airdrops.\nLooking ahead, we also plan to introduce an ELO rating system with ranked divisions\u2014adding a competitive layer that rewards performance and progression over time.\nGetting Involved\nEveryone is welcome to join our Telegram chat: Telegram: View @mortalcoin_chat and share suggestions or ideas.\nRight now, we\u2019re in the middle of transitioning our backend from Telegram Mini App support to a full web experience. We anticipate a playable web version with engaging gameplay and on-chain mechanics to be ready by the end of July - and we\u2019ll need plenty of help testing and playing!"
            },
            {
                "author": "LazAI_Helper_bot",
                "comment": "This sounds like a really interesting project, Tony! The concept of turning crypto trading into a fighting game with real-time simulation and on-chain verification is quite innovative.\nHere are a few thoughts and potential discussion points for you, based on your post:\nMetis Hyperion Integration: You mentioned deploying your first on-chain logic using Metis\u2019s Hyperion. This is a great way to leverage the speed and security of the Metis L2 network. I\u2019m curious about what specific gameplay elements you plan to make cryptographically verifiable. Are you thinking about verifiable randomness for match outcomes, or perhaps on-chain escrow for in-game assets?\nCommunity Engagement: The leaderboards, referral system, and missions are excellent for driving user engagement. Have you considered any tokenomics or NFT integration strategies to further incentivize participation and long-term retention?\nTechnical Challenges: Transitioning from a Telegram Mini App to a full web app while maintaining real-time gameplay and integrating on-chain mechanics sounds technically challenging. What are some of the biggest hurdles you\u2019re anticipating, and how are you planning to address them?\nI\u2019d also recommend sharing this project in the #ideation channel on the LazAI Discord. There are a lot of knowledgeable people there who could provide valuable feedback and suggestions.\nTo find the discord, you can use this search query: LazAI Discord"
            },
            {
                "author": "tonymorony",
                "comment": "We started active R&D at the beginning of the week and already have a progress, including initial brainstorm results and implementation planning (game sequence diagram attached)\nThe current flow idea for on-chain gameplay is as follows:\nConcept\nWe aim to build a secure, manipulation-resistant PvP arena using EVM-compatible smart contracts. All core actions such as betting, creating and joining games, opening/closing positions, and finalizing are performed on-chain. The backend plays a supporting role: validating on-chain activity, relaying messages between players, and tracking game states.\nBackend Responsibilities\nEvent Listener\nListens to smart contract events\nTracks and syncs game states (pending, active, completed) with a centralized DB\nKeeps game data fresh for frontend UX (matchmaking, game history, rewards)\nRemoves games if the creator goes offline\nGame Status and Matchmaking API\n/api/game/create validates initGame transactions\n/games/waiting-for-opponent returns available games to join\n/api/game/start validates joinGame transactions\nSignature Relay\n/api/position/signature provides backend EIP-712 signature for opening positions\nWebSocket or long polling is used to relay signature requests:\nPlayer 2 \u2192 Backend \u2192 Player 1 \u2192 (Signs) \u2192 Backend \u2192 Player 2\nGame Watchdog\nTracks whether the game creator (Player 1) is online\nHides the game from the list if the creator is offline\nDuring joinGame, the contract validates Player 1\u2019s short-TTL signature, proving they were online and approved the join\nFrontend Responsibilities\nGame Start\nUser clicks \u201cStart Fight\u201d and selects a fighter\nFrontend queries /games/waiting-for-opponent\nIf a game is found, it requests a join signature from Player 1 via backend\nIf no game is found, frontend calls initGame(poolAddress, betAmount)\nAfter the transaction is confirmed, backend validates it via /api/game/create\nMatchmaking UI\nDisplays a waiting screen with a countdown\nOptionally subscribes to real-time updates via WebSocket\nIn-Game Trading\nopenHashedPosition(gameId, directionHash, backendSignature) is used to open a position (direction is hidden initially)\nSignature is retrieved from /api/position/signature\nclosePosition(gameId, direction, nonce) is used to reveal and close the position\nFinalization\nOnce both players have closed their positions, the creator finalizes the game via finalizeGame(gameId)\nIf someone is unresponsive, backend triggers forced finalization after timeout\nSmart Contract Core Functions\ninitGame(poolAddress, betAmount) locks the bet and creates a game\njoinGame(gameId, poolAddress, betAmount, joinSignature) lets the second player join\nopenHashedPosition(gameId, directionHash, backendSignature) opens a hashed position\nclosePosition(gameId, direction, nonce) reveals and settles the position\nfinalizeGame(gameId) settles rewards and closes the game\nGame Pool Whitelist\nThe contract stores a whitelist of allowed DEX pools for each network\nOnly the owner can modify the list to prevent use of fake or manipulatable pools\nThe contract uses these whitelisted pools to fetch real-time prices for PnL and trade validation\nOpen Questions\nHow to efficiently track intermediate game state (e.g., opponent\u2019s position, PnL) \u2014 will likely be handled off-chain via event polling\nFail-safes and abuse prevention:\nJoin TTL signatures required from Player 1\nFirst-come, first-serve enforcement on backend and contract\nPool whitelist enforced in contract\nSecurity Measures\nOnly whitelisted pools are used\nAll actions require confirmed on-chain transactions\nTTL-based join signatures ensure liveness and prevent stolen entries\nBackend signs position hashes to enable forced closure if needed"
            }
        ]
    },
    {
        "id": "76b51b6c3e807589",
        "topic_id": "6288",
        "title": "No Risk PoT",
        "url": "https://forum.ceg.vote/t/no-risk-pot/6288",
        "views": "",
        "comments": "1",
        "created_date": "Jul 11, 2025 6:59 am",
        "latest_activity": "Jul 11, 2025 6:59 am",
        "content": "Project Title:\nNo Risk Pot \u2013 A No-Loss DeFi Lottery on Hyperion\nProblem Statement:\nTraditional lotteries and DeFi platforms suffer from two major limitations:\nHigh risk for users \u2013 Participants lose their money if they don\u2019t win.\nLack of accessible, real-world financial use cases \u2013 DeFi tools are often complex and disconnected from everyday utility, discouraging mainstream adoption.\nThere\u2019s a growing need for risk-free, gamified DeFi products that can engage users, preserve capital, and unlock broader financial participation \u2014 especially on emerging chains like Hyperion that aim to grow their active user base.\nSolution Overview:\nNo Risk Pot is a fully decentralized lottery platform deployed on the Hyperion blockchain, where users participate without risking their principal funds.\nAll ticket purchases are pooled and deployed into Hyperion-native or integrated DeFi protocols to generate yield. The lottery prizes are then distributed only from the interest earned, not the user deposits. This ensures that all users receive their original investment back, creating a risk-free and rewarding experience.\nBy offering a seamless, no-loss mechanism built on Hyperion, this project encourages more users, capital flow, and real-world utility on the chain.\nProject Description:\nUsers purchase lottery tickets using a stable asset supported by the Hyperion ecosystem.\nThe pooled funds are invested in safe, yield-generating DeFi strategies on Hyperion.\nAt the end of each lottery round:\nFirst prize: 50% of the total yield\nSecond prize: 30%\nPlatform fee: 20% (for sustainability and further development)\nAll users get 100% of their original funds back, regardless of lottery results.\nDeployed on the Hyperion blockchain, No Risk Pot utilizes its scalability, low fees, and fast transaction finality to provide a smooth, user-friendly experience. This project not only brings a unique financial game to DeFi but also attracts new wallets, liquidity, and real engagement to Hyperion.\nCommunity Engagement Features:\nTransparent on-chain prize draws and yield tracking\nCommunity voting for upcoming investment strategies and lottery rules\nEducational guides and simulations to onboard non-crypto users\nReferral and ambassador programs to grow adoption and wallet activity on Hyperion\nWhy Hyperion Benefits from This Project:\nEncourages frequent wallet activity and capital retention on-chain\nShowcases real utility for stable assets and DeFi on Hyperion\nOffers a fun, low-risk entry point for new users exploring blockchain\nCreates a model easily extensible to Hyperion-based card, credit, or yield tools",
        "comments_details": [
            {
                "author": "rahul_iiitv",
                "comment": "Project Title:\nNo Risk Pot \u2013 A No-Loss DeFi Lottery on Hyperion\nProblem Statement:\nTraditional lotteries and DeFi platforms suffer from two major limitations:\nHigh risk for users \u2013 Participants lose their money if they don\u2019t win.\nLack of accessible, real-world financial use cases \u2013 DeFi tools are often complex and disconnected from everyday utility, discouraging mainstream adoption.\nThere\u2019s a growing need for risk-free, gamified DeFi products that can engage users, preserve capital, and unlock broader financial participation \u2014 especially on emerging chains like Hyperion that aim to grow their active user base.\nSolution Overview:\nNo Risk Pot is a fully decentralized lottery platform deployed on the Hyperion blockchain, where users participate without risking their principal funds.\nAll ticket purchases are pooled and deployed into Hyperion-native or integrated DeFi protocols to generate yield. The lottery prizes are then distributed only from the interest earned, not the user deposits. This ensures that all users receive their original investment back, creating a risk-free and rewarding experience.\nBy offering a seamless, no-loss mechanism built on Hyperion, this project encourages more users, capital flow, and real-world utility on the chain.\nProject Description:\nUsers purchase lottery tickets using a stable asset supported by the Hyperion ecosystem.\nThe pooled funds are invested in safe, yield-generating DeFi strategies on Hyperion.\nAt the end of each lottery round:\nFirst prize: 50% of the total yield\nSecond prize: 30%\nPlatform fee: 20% (for sustainability and further development)\nAll users get 100% of their original funds back, regardless of lottery results.\nDeployed on the Hyperion blockchain, No Risk Pot utilizes its scalability, low fees, and fast transaction finality to provide a smooth, user-friendly experience. This project not only brings a unique financial game to DeFi but also attracts new wallets, liquidity, and real engagement to Hyperion.\nCommunity Engagement Features:\nTransparent on-chain prize draws and yield tracking\nCommunity voting for upcoming investment strategies and lottery rules\nEducational guides and simulations to onboard non-crypto users\nReferral and ambassador programs to grow adoption and wallet activity on Hyperion\nWhy Hyperion Benefits from This Project:\nEncourages frequent wallet activity and capital retention on-chain\nShowcases real utility for stable assets and DeFi on Hyperion\nOffers a fun, low-risk entry point for new users exploring blockchain\nCreates a model easily extensible to Hyperion-based card, credit, or yield tools"
            },
            {
                "author": "LazAI_Helper_bot",
                "comment": "This looks like a solid project proposal for a \u201cNo Risk Pot\u201d DeFi lottery on the Hyperion blockchain. Rahul_iiitv has clearly articulated the problem, solution, and potential benefits. Here are a few thoughts and questions that might be helpful:\nStrengths:\nClear Problem Definition: The problem of risk in traditional lotteries and DeFi is well-defined.\nInnovative Solution: The no-loss lottery concept is compelling and addresses a significant barrier to entry for new users.\nBenefits to Hyperion: The proposal clearly outlines how the project can benefit the Hyperion ecosystem.\nCommunity Engagement: The listed community engagement features are excellent for driving adoption.\nPotential Questions/Considerations:\nSpecific DeFi Strategies: Which specific DeFi protocols on Hyperion will be used for yield generation? Detailing the safety and stability of these protocols would strengthen the proposal.\nPlatform Fee Justification: While a 20% platform fee seems reasonable for sustainability, providing a breakdown of how the fee will be used (e.g., development, marketing, security audits) could further justify it.\nScalability and Gas Costs: Even with Hyperion\u2019s scalability, gas costs could be a factor. How will the platform optimize for gas efficiency, especially with a large number of participants?\nSecurity Considerations: What security measures will be implemented to protect the pooled funds and prevent exploits?\nRegulatory Compliance: Are there any regulatory considerations or compliance measures that need to be addressed?\nSmart Contract Architecture: A high-level overview of the smart contract architecture would be helpful.\nOverall:\nThis is a well-thought-out project idea with the potential to attract new users and capital to the Hyperion blockchain. Addressing the questions above would make the proposal even stronger. It would be good to see Rahul expand on the specific strategies for yield generation and the security measures that will be in place. Good luck with the Ideathon!"
            }
        ]
    },
    {
        "id": "7f62a3b0cb7c782e",
        "topic_id": "6287",
        "title": "A New Era of GPU & AI Agent Renting - DanteGPU",
        "url": "https://forum.ceg.vote/t/a-new-era-of-gpu-ai-agent-renting-dantegpu/6287",
        "views": "",
        "comments": "1",
        "created_date": "Jul 11, 2025 12:24 am",
        "latest_activity": "Jul 11, 2025 12:24 am",
        "content": "Introduction\nDanteGPU is a GPU-as-a-Service (GPUaaS) project designed to democratize access to high-performance computing. At its core, DanteGPU enables individuals and entities to monetize their unused graphics card capabilities by renting them to a distributed network. Users of the platform can earn $dGPU tokens for providing these resources.\nThe project features Agora, an all-in-one Agent marketplace, and emphasizes AI interoperability. This allows users to access and utilize various AI Agents on a pay-per-use basis, billed hourly, thereby avoiding hefty monthly subscription costs. Furthermore, DanteGPU empowers users to publish their own AI agents on the Agora marketplace, fostering a rich ecosystem of AI tools and services.\nCore Mission: DanteGPU aims to dismantle the centralized control currently held by a few major players in the AI and high-performance computing landscape. By eliminating central points of control, the project strives to make powerful GPU resources accessible to everyone, from individual AI hobbyists and researchers to small development teams. https://app.gitbook.com/o/G99KZfPVvkpFW0qw5X5t/s/7ZpP0HETQD2EI5hgSjvt/~/changes/10/dantegpu-backend/core-services\nKey Tenets of DanteGPU:\nDemocratized GPU Access: GPU providers can directly offer their unused resources to AI developers and researchers, ensuring fair and efficient access to computing power without intermediaries.\nReal-Time Access to Distributed GPU Resources:  AI agents can instantly discover available GPU resources through a blockchain-powered marketplace (Agora) and scale their workloads efficiently.\nAutonomous GPU Selection & Optimization: AI agents are empowered to select GPUs based on specific criteria such as VRAM, processing power, and bandwidth requirements, while also optimizing for cost and performance.\nFlexible Usage Model & Lower Costs: DanteGPU champions a pay-as-you-go model, removing the need for long-term subscription commitments typically found in traditional cloud GPU services.\nAccelerated Model Training: The distributed nature of DanteGPU\u2019s resources allows for the parallelization of AI model training workloads across multiple GPUs, significantly speeding up development cycles.\nSecure & Transparent Transactions: Leveraging the Solana blockchain, DanteGPU ensures that all transactions between GPU providers and AI agents are transparent, immutable, and securely recorded.\nThis documentation will guide you through the various aspects of the DanteGPU project, including its architecture, components, and how to participate as a user or provider.\nProject Vision, Scope, and Target Audience\nThis section provides a deeper insight into the fundamental goals of the DanteGPU platform, the specific challenges it addresses, the key parties involved in its development, and its intended users, with a clear distinction for its AI marketplace product, Agora.\nProject Name and Core Concept\nDanteGPU is a comprehensive platform built on the Solana blockchain, designed to democratize access to GPU resources and AI capabilities. A key product within the DanteGPU ecosystem is Agora, an open marketplace for AI agents, chatbots, and AI-enhanced applications. The platform as a whole aims to create a environment where providers can offer GPU power and AI tools, and consumers can access them using the unified utility token, $dGPU.\nPrimary Business Problem Addressed\nThe current AI landscape is predominantly controlled by a handful of large corporations possessing extensive computational resources. This centralization creates barriers to entry and innovation for smaller entities and individuals. The DanteGPU platform, through its products and services including the Agora Marketplace, aims to address this critical business pain point by:\nDemocratizing Access to AI Tools: Allowing anyone, from individual developers to research institutions, to publish their AI-enhanced tools (AI-powered applications, chatbots, image generators, agents, etc.) on Agora, DanteGPU\u2019s open marketplace.\nDemocratizing Access to GPU Power: Enabling individuals and entities to rent out their unused GPU capacity to the network, making high-performance computing more accessible.\nUnifying Utility: Enabling users to access a diverse range of AI-enhanced tools on Agora and GPU resources using a single, central utility token, $dGPU, simplifying transactions and fostering a cohesive ecosystem.\nBy tackling these issues, DanteGPU seeks to foster a more equitable, innovative, and accessible AI ecosystem.\nKey Stakeholders\nWhile originating as a hackathon project that did not secure grant funding, the DanteGPU platform is under continuous and active development by its original founding team. This team remains the primary group invested in the project\u2019s success, driving its vision, development, and future growth. As the platform evolves, other stakeholders will include:\nGPU Providers: Individuals and entities who rent out their GPU resources to the DanteGPU network.\nAI Tool Publishers/Providers on Agora : Developers and organizations who list their AI agents and applications on the Agora Marketplace .\nConsumers/End-Users: Individuals and businesses who utilize the AI tools on Agora and GPU resources available through the DanteGPU platform.\n$dGPU Token Holders: Individuals invested in the ecosystem\u2019s utility and growth.\nProject Timeline and Constraints (Current Status)\nThe initial roadmap for the DanteGPU platform includes the target of a beta launch for the Agora marketplace approximately seven month from the project\u2019s effective restart (post-hackathon development phase), followed by a public release after an additional month of rigorous testing and refinement.\nCurrent known challenges and constraints for the DanteGPU platform include:\nExpertise Gaps: Limitations in specialized knowledge concerning system architecture for high-availability systems.\nScalability Engineering: Designing and maintaining web infrastructure capable of handling high traffic volumes, particularly for Agora.\nBlockchain Operations: Managing a live blockchain product that involves real-time payment processing for both GPU rental and Agora Marketplace transactions, and the handling of sensitive user and transaction data.\nThese areas are actively being addressed by the development team.\nExpected Business Outcomes and Success Metrics\nThe success of the DanteGPU platform will be measured by a combination of platform adoption, ecosystem growth (for both GPU sharing and Agora), and token utility. Key metrics include:\nUser Acquisition: The total number of registered users on the platform (both consumers and providers of GPU resources and AI tools).\nMarketplace Activity ( Agora ): The number of unique AI-enhanced applications and agents published on Agora.\nGPU Resource Utilization: The amount of GPU compute time rented through the platform.\nProvider Earnings: The cumulative amount of $dGPU earned by AI tool creators on Agora and GPU providers.\nToken Velocity & Valuation: The indirect increase in $dGPU\u2019s market capitalization (MCAP) as a reflection of platform utility, driven by consumers exchanging $dGPU for services (potentially via $SOL or other pairs) and creators/providers being rewarded in $dGPU.\nAdditional relevant metrics may be identified and incorporated as the platform matures.\nTarget Audiences\nThe DanteGPU platform is designed to serve two primary groups, particularly concerning its Agora marketplace and GPU rental services:\nFor AI Tool Creators/Publishers (on Agora):\nThe ideal publisher for the Agora Marketplace includes, but is not limited to:\nIndividual AI Hobbyists: Enthusiasts developing novel or niche AI tools.\nSmall AI Development Teams: Startups and independent teams creating specialized AI solutions.\nAcademic Researchers: Institutions and researchers looking to share their AI models and tools with a broader audience or monetize their research via Agora.\nDevelopers of Foundational Models: Those who wish to provide access to large, pre-trained language models that can serve as a base for various specialized tasks through Agora.\nFor GPU Providers (on DanteGPU):\nIndividuals with powerful gaming PCs or mining rigs with idle GPU capacity.\nSmall to medium-sized data centers or businesses with underutilized GPU servers.\nResearchers or institutions with specialized GPU hardware available for specific tasks.\nFor End-Users (Consumers on DanteGPU & Agora):\nThe primary target end-users for the AI tools available on Agora and the GPU resources on the DanteGPU platform are:\nBusinesses: Companies of all sizes seeking to integrate AI capabilities (via Agora) or access raw GPU power for model training/inference without significant upfront investment in hardware or complex monthly subscriptions.\nIndividual Consumers: Users looking for specific AI tools on Agora for personal use, creative endeavors, or learning purposes, or individuals needing temporary GPU power.\nDevelopers: Programmers and software engineers who wish to integrate AI functionalities from Agora into their own applications or require GPU resources for their development projects.\nAI Developers and Researchers: Those needing access to diverse and scalable GPU resources for training complex models or running intensive simulations.\nArchitectural Overview\nThe DanteGPU platform is engineered as a distributed system, with its backend services forming the operational core responsible for orchestrating GPU resources, managing AI workloads, ensuring secure access, and facilitating a seamless user experience within the Agora marketplace and the broader GPU-as-a-Service (GPUaaS) ecosystem. The architecture is predicated on modern principles of microservices, robust communication patterns, and a carefully selected technology stack to achieve high availability, scalability, and maintainability.\nI. Architectural Paradigm: Decentralized Microservices\nThe DanteGPU backend eschews a monolithic structure in favor of a microservices architecture. This paradigm involves decomposing the application into a suite of small, independently deployable services, each organized around a specific business capability or domain. This choice is foundational to achieving the platform\u2019s goals of democratization and distributed operation.\nA. Rationale and Benefits:\nEnhanced Scalability & Elasticity: Each microservice can be scaled independently (e.g., horizontally by adding more instances or vertically by allocating more resources) based on its specific load profile. For instance, the Job Queue Service might require different scaling characteristics during peak submission times than the Authentication Service. This granular scalability ensures optimal resource utilization and cost-effectiveness.\nImproved Fault Isolation & Resilience: The failure of a single microservice, if designed correctly with patterns like circuit breakers or bulkheads (though specific implementations depend on service logic), is less likely to cause a catastrophic failure of the entire platform. This resilience is paramount for a system managing real-time GPU access and financial transactions ($dGPU).\nTechnology Diversity & Specialization: While the primary languages are Go and Python (FastAPI), a microservices approach theoretically allows for selecting the best technology (language, database, etc.) for each service\u2019s specific needs without impacting others. This fosters innovation and allows developers to leverage optimal tools for particular problems. For example, Go\u2019s concurrency primitives and performance are ideal for network-intensive services like the API Gateway or resource orchestration, while Python\u2019s rich ecosystem and rapid development capabilities suit services like user authentication or business logic layers.\nIndependent Development & Deployment Cycles: Teams can develop, test, and deploy their respective microservices autonomously. This accelerates development velocity, simplifies continuous integration/continuous deployment (CI/CD) pipelines, and reduces the scope and risk of individual deployments.\nClearer Domain Boundaries (Domain-Driven Design - DDD): Microservices naturally align with DDD principles, where service boundaries are defined around specific business domains (e.g., User Management, GPU Resource Management, Job Lifecycle Management). This leads to services with high cohesion and loose coupling, making the system easier to understand, evolve, and maintain.\nAlignment with Decentralization Ethos: A distributed network of services mirrors the decentralized nature of the GPU providers and consumers DanteGPU aims to connect.\nB. Inherent Challenges and Mitigation Strategies:\nAdopting microservices also introduces complexities that the DanteGPU architecture must address:\nOperational Overhead: Managing a multitude of services requires robust automation for deployment, scaling, monitoring, and logging. Technologies like Docker, Docker Compose, and a future transition to Kubernetes are key to mitigating this.\nDistributed System Complexity: Debugging and tracing requests across multiple service boundaries can be challenging. Implementing distributed tracing (e.g., using OpenTelemetry) and comprehensive, correlated logging are essential.\nInter-Service Communication: Network latency, reliability, and the need for robust communication patterns (discussed below) become critical concerns.\nData Consistency: Maintaining data consistency across services that own their respective databases requires careful design, often employing patterns like eventual consistency, sagas, or two-phase commits where strong consistency is indispensable.\nTesting Complexity: End-to-end testing of workflows spanning multiple services requires more sophisticated strategies than testing a monolith.\nII. Inter-Service Communication Strategy\nEffective communication between microservices is vital. DanteGPU employs a hybrid approach, leveraging both synchronous and asynchronous patterns:\nA. Synchronous Communication:\nUsed for request/response interactions where an immediate response is expected.\ngRPC (Google Remote Procedure Call):\nRationale: Preferred for internal, high-throughput, low-latency communication between backend services.\nMechanism: Utilizes HTTP/2 for transport, offering multiplexing, header compression, and bidirectional streaming. Protocol Buffers (Protobufs) are used as the Interface Definition Language (IDL), enforcing contract-first design, ensuring type safety, and enabling efficient binary serialization/deserialization.\nBenefits: High performance, efficient data encoding, strongly-typed contracts, support for streaming, and code generation in multiple languages.\nUse Cases: Internal API calls between core services like the Scheduler/Orchestrator Service querying the Provider Registry Service for available GPUs, or internal control plane operations.\nRESTful APIs (HTTP/JSON):\nRationale: Employed for services that might be consumed by a wider range of clients (including potentially third-party developers in the future) or where the overhead of gRPC setup is not justified. The API Gateway also exposes RESTful endpoints to external clients.\nMechanism: Standard HTTP methods (GET, POST, PUT, DELETE) with JSON payloads. Adherence to REST principles (statelessness, resource-based URLs) is expected.\nBenefits: Simplicity, ubiquity, human-readability (JSON), wide support across languages and tools, easier integration with web frontends.\nUse Cases: External API Gateway endpoints, specific internal services where simplicity is prioritized over raw performance, or interaction with services like the Authentication Service from the API Gateway.\nB. Asynchronous Communication / Event-Driven Architecture:\nUsed for decoupling services, improving resilience, and handling long-running or background tasks. This is crucial for a system managing potentially time-consuming AI jobs.\nNATS JetStream:\nRationale: Provides a persistent, reliable, and high-performance messaging and streaming platform for asynchronous operations.\nMechanism: NATS is a lightweight, high-performance messaging system. JetStream adds persistence, message replay, and various delivery semantics (at-least-once, at-most-once, and potentially exactly-once patterns depending on consumer logic). Services publish events/messages to named \u201csubjects\u201d (topics), and interested services subscribe to these subjects.\nStreams: Persistent logs of messages.\nConsumers: Allow services to read messages from streams, with options for push or pull delivery, acknowledgments, and durable subscriptions.\nBenefits:\nDecoupling: Producers and consumers are independent; they don\u2019t need to know about each other or be available simultaneously.\nResilience & Durability: Message persistence ensures that requests are not lost if a consuming service is temporarily unavailable.\nScalability: Allows for scaling consumer groups independently to process messages in parallel.\nLoad Leveling: Smooths out peak loads by queuing requests.\nUse Cases:\nJob Queuing: The Job Queue Service relies on NATS JetStream to persist AI job requests submitted by users. The Scheduler/Orchestrator Service consumes these jobs from the queue.\nEvent Notification: Broadcasting events like \u201cGPU available,\u201d \u201cjob status updated,\u201d or \u201cnew model published on Agora\u201d to interested services without direct coupling.\nData Pipelines: Facilitating asynchronous data flows, e.g., logs or metrics forwarding before final aggregation.\nIII. Core Technology Stack Choices\nThe selection of technologies for the DanteGPU backend reflects a pragmatic approach, balancing performance, developer productivity, and ecosystem support.\nGo (Golang):\nRole: Primary language for high-performance, concurrent network services and infrastructure components.\nStrengths: Excellent support for concurrency (goroutines, channels), compiled to native code for speed, static typing for reliability, efficient memory management, and a strong standard library for networking. Ideal for services like the API Gateway (Siger), Provider Registry Service, and Scheduler/Orchestrator Service.\nPython (with FastAPI):\nRole: Used for services where rapid development, a rich ecosystem of libraries (e.g., for machine learning, data science, web frameworks), or specific integrations are key.\nStrengths (FastAPI): Modern, high-performance web framework for building APIs with Python 3.7+ based on standard Python type hints. Offers automatic data validation, serialization, interactive API documentation (Swagger UI, ReDoc), and leverages Starlette (for web parts) and Pydantic (for data parts). Ideal for the Authentication Service.\nDocker & Docker Compose:\nRole: Containerization technology for packaging applications and their dependencies. Docker Compose is used for defining and running multi-container Docker applications, especially in development and testing environments.\nBenefits: Environment consistency, isolation, portability across machines, simplified dependency management, and a foundational step towards more advanced orchestration.\nConsul (by HashiCorp):\nRole: Service discovery, configuration management, and health checking.\nMechanism: Services register themselves with Consul, and other services can query Consul to find their network locations. Consul performs health checks to ensure only healthy service instances receive traffic. It can also serve as a distributed key-value store for dynamic configuration.\nBenefits: Enables dynamic scaling and resilience, as services don\u2019t need hardcoded addresses. Simplifies the routing logic in the API Gateway and internal service communication.\nPostgreSQL:\nRole: Robust, open-source object-relational database system used for persistent storage by services requiring structured data and transactional integrity.\nStrengths: ACID compliance, reliability, extensibility, rich feature set (JSONB support, full-text search, etc.). Suitable for the Provider Registry Service, Scheduler/Orchestrator Service (job store), and Authentication Service (user data).\nMinIO:\nRole: High-performance, S3-compatible object storage service.\nStrengths: Scalable, resilient storage for unstructured data like AI models, datasets, job results, and user uploads. Can be self-hosted, providing data sovereignty.\nKubernetes (Future Consideration):\nRole: Advanced container orchestration platform.\nBenefits: Automated deployment, scaling, self-healing, service discovery, load balancing, and configuration management for containerized applications at scale. A natural evolution from Docker Compose for production environments demanding higher resilience and operational efficiency.\nIV. Overview of Core Service Domains\nThe backend is logically segmented into several domains, each encompassing one or more microservices:\nAPI Gateway ( siger-api-gateway ): The unified ingress point. Handles routing, authentication (JWT), rate limiting, CORS, and acts as a facade for the backend services. (To be detailed in Page 5).\nAuthentication Service ( auth-service ): Manages user identities (providers, consumers), registration, credential verification (password hashing), JWT issuance, and potentially profile management.\nProvider Registry Service ( provider-registry-service ): Tracks connected GPU providers, their hardware specifications (GPU model, VRAM, drivers), real-time status (idle, busy), location, and utilization metrics. Critical for the scheduler to find suitable resources.\nJob Queue Service (Integrated via NATS): Manages the intake and persistent queuing of AI job requests.\nScheduler/Orchestrator Service ( scheduler-orchestrator-service ): The \u201cbrain\u201d of the system. Dequeues jobs, queries the Provider Registry for suitable GPUs, dispatches tasks (likely via NATS) to provider daemons (beatrice-core-services), and tracks job progress.\nStorage Service ( storage-service ): Abstracts interactions with object storage (MinIO), handling uploads, downloads, and management of models, datasets, and results.\nMonitoring & Logging Service ( monitoring-logging-service ): A stack (Prometheus, Grafana, Loki, Promtail, etc.) for aggregating metrics and logs from all services, enabling observability and debugging.\nGPU Provider Daemon ( beatrice-core-services ): A client-side agent running on the GPU provider\u2019s machine. Responsible for receiving tasks from the Scheduler, executing them (e.g., in a containerized environment with GPU passthrough), monitoring execution, and reporting back results and status. (This component is critical for the GPUaaS functionality).\nBilling & Payment Service (Planned Post-MVP): Will integrate with payment gateways to track resource usage (GPU time, storage) and manage financial transactions (payouts to providers, charges to consumers).\nV. Cross-Cutting Concerns\nSeveral concerns span multiple services:\nSecurity: Beyond authentication/authorization, includes secure inter-service communication (e.g., mTLS), input validation, protection against common vulnerabilities, and secure secrets management.\nObservability:\nLogging: Consistent, structured logging across all services, often correlated with request IDs for tracing.\nMetrics: Collection of key performance indicators (KPIs) from each service for monitoring health and performance.\nDistributed Tracing: Implementing mechanisms (e.g., OpenTelemetry) to trace requests as they flow through multiple services.\nConfiguration Management: Centralized and dynamic configuration for services, potentially using Consul\u2019s KV store or environment variables managed by the orchestration platform.\nError Handling & Resilience: Consistent error reporting, retry mechanisms, and fault tolerance patterns within and between services.\nFor more information:\nX -> https://x.com/dantegpuaas\nGithub Organization (Star Us) \u2192 DanteGPU \u00b7 GitHub",
        "comments_details": [
            {
                "author": "makinci",
                "comment": "Introduction\nDanteGPU is a GPU-as-a-Service (GPUaaS) project designed to democratize access to high-performance computing. At its core, DanteGPU enables individuals and entities to monetize their unused graphics card capabilities by renting them to a distributed network. Users of the platform can earn $dGPU tokens for providing these resources.\nThe project features Agora, an all-in-one Agent marketplace, and emphasizes AI interoperability. This allows users to access and utilize various AI Agents on a pay-per-use basis, billed hourly, thereby avoiding hefty monthly subscription costs. Furthermore, DanteGPU empowers users to publish their own AI agents on the Agora marketplace, fostering a rich ecosystem of AI tools and services.\nCore Mission: DanteGPU aims to dismantle the centralized control currently held by a few major players in the AI and high-performance computing landscape. By eliminating central points of control, the project strives to make powerful GPU resources accessible to everyone, from individual AI hobbyists and researchers to small development teams. https://app.gitbook.com/o/G99KZfPVvkpFW0qw5X5t/s/7ZpP0HETQD2EI5hgSjvt/~/changes/10/dantegpu-backend/core-services\nKey Tenets of DanteGPU:\nDemocratized GPU Access: GPU providers can directly offer their unused resources to AI developers and researchers, ensuring fair and efficient access to computing power without intermediaries.\nReal-Time Access to Distributed GPU Resources:  AI agents can instantly discover available GPU resources through a blockchain-powered marketplace (Agora) and scale their workloads efficiently.\nAutonomous GPU Selection & Optimization: AI agents are empowered to select GPUs based on specific criteria such as VRAM, processing power, and bandwidth requirements, while also optimizing for cost and performance.\nFlexible Usage Model & Lower Costs: DanteGPU champions a pay-as-you-go model, removing the need for long-term subscription commitments typically found in traditional cloud GPU services.\nAccelerated Model Training: The distributed nature of DanteGPU\u2019s resources allows for the parallelization of AI model training workloads across multiple GPUs, significantly speeding up development cycles.\nSecure & Transparent Transactions: Leveraging the Solana blockchain, DanteGPU ensures that all transactions between GPU providers and AI agents are transparent, immutable, and securely recorded.\nThis documentation will guide you through the various aspects of the DanteGPU project, including its architecture, components, and how to participate as a user or provider.\nProject Vision, Scope, and Target Audience\nThis section provides a deeper insight into the fundamental goals of the DanteGPU platform, the specific challenges it addresses, the key parties involved in its development, and its intended users, with a clear distinction for its AI marketplace product, Agora.\nProject Name and Core Concept\nDanteGPU is a comprehensive platform built on the Solana blockchain, designed to democratize access to GPU resources and AI capabilities. A key product within the DanteGPU ecosystem is Agora, an open marketplace for AI agents, chatbots, and AI-enhanced applications. The platform as a whole aims to create a environment where providers can offer GPU power and AI tools, and consumers can access them using the unified utility token, $dGPU.\nPrimary Business Problem Addressed\nThe current AI landscape is predominantly controlled by a handful of large corporations possessing extensive computational resources. This centralization creates barriers to entry and innovation for smaller entities and individuals. The DanteGPU platform, through its products and services including the Agora Marketplace, aims to address this critical business pain point by:\nDemocratizing Access to AI Tools: Allowing anyone, from individual developers to research institutions, to publish their AI-enhanced tools (AI-powered applications, chatbots, image generators, agents, etc.) on Agora, DanteGPU\u2019s open marketplace.\nDemocratizing Access to GPU Power: Enabling individuals and entities to rent out their unused GPU capacity to the network, making high-performance computing more accessible.\nUnifying Utility: Enabling users to access a diverse range of AI-enhanced tools on Agora and GPU resources using a single, central utility token, $dGPU, simplifying transactions and fostering a cohesive ecosystem.\nBy tackling these issues, DanteGPU seeks to foster a more equitable, innovative, and accessible AI ecosystem.\nKey Stakeholders\nWhile originating as a hackathon project that did not secure grant funding, the DanteGPU platform is under continuous and active development by its original founding team. This team remains the primary group invested in the project\u2019s success, driving its vision, development, and future growth. As the platform evolves, other stakeholders will include:\nGPU Providers: Individuals and entities who rent out their GPU resources to the DanteGPU network.\nAI Tool Publishers/Providers on Agora : Developers and organizations who list their AI agents and applications on the Agora Marketplace .\nConsumers/End-Users: Individuals and businesses who utilize the AI tools on Agora and GPU resources available through the DanteGPU platform.\n$dGPU Token Holders: Individuals invested in the ecosystem\u2019s utility and growth.\nProject Timeline and Constraints (Current Status)\nThe initial roadmap for the DanteGPU platform includes the target of a beta launch for the Agora marketplace approximately seven month from the project\u2019s effective restart (post-hackathon development phase), followed by a public release after an additional month of rigorous testing and refinement.\nCurrent known challenges and constraints for the DanteGPU platform include:\nExpertise Gaps: Limitations in specialized knowledge concerning system architecture for high-availability systems.\nScalability Engineering: Designing and maintaining web infrastructure capable of handling high traffic volumes, particularly for Agora.\nBlockchain Operations: Managing a live blockchain product that involves real-time payment processing for both GPU rental and Agora Marketplace transactions, and the handling of sensitive user and transaction data.\nThese areas are actively being addressed by the development team.\nExpected Business Outcomes and Success Metrics\nThe success of the DanteGPU platform will be measured by a combination of platform adoption, ecosystem growth (for both GPU sharing and Agora), and token utility. Key metrics include:\nUser Acquisition: The total number of registered users on the platform (both consumers and providers of GPU resources and AI tools).\nMarketplace Activity ( Agora ): The number of unique AI-enhanced applications and agents published on Agora.\nGPU Resource Utilization: The amount of GPU compute time rented through the platform.\nProvider Earnings: The cumulative amount of $dGPU earned by AI tool creators on Agora and GPU providers.\nToken Velocity & Valuation: The indirect increase in $dGPU\u2019s market capitalization (MCAP) as a reflection of platform utility, driven by consumers exchanging $dGPU for services (potentially via $SOL or other pairs) and creators/providers being rewarded in $dGPU.\nAdditional relevant metrics may be identified and incorporated as the platform matures.\nTarget Audiences\nThe DanteGPU platform is designed to serve two primary groups, particularly concerning its Agora marketplace and GPU rental services:\nFor AI Tool Creators/Publishers (on Agora):\nThe ideal publisher for the Agora Marketplace includes, but is not limited to:\nIndividual AI Hobbyists: Enthusiasts developing novel or niche AI tools.\nSmall AI Development Teams: Startups and independent teams creating specialized AI solutions.\nAcademic Researchers: Institutions and researchers looking to share their AI models and tools with a broader audience or monetize their research via Agora.\nDevelopers of Foundational Models: Those who wish to provide access to large, pre-trained language models that can serve as a base for various specialized tasks through Agora.\nFor GPU Providers (on DanteGPU):\nIndividuals with powerful gaming PCs or mining rigs with idle GPU capacity.\nSmall to medium-sized data centers or businesses with underutilized GPU servers.\nResearchers or institutions with specialized GPU hardware available for specific tasks.\nFor End-Users (Consumers on DanteGPU & Agora):\nThe primary target end-users for the AI tools available on Agora and the GPU resources on the DanteGPU platform are:\nBusinesses: Companies of all sizes seeking to integrate AI capabilities (via Agora) or access raw GPU power for model training/inference without significant upfront investment in hardware or complex monthly subscriptions.\nIndividual Consumers: Users looking for specific AI tools on Agora for personal use, creative endeavors, or learning purposes, or individuals needing temporary GPU power.\nDevelopers: Programmers and software engineers who wish to integrate AI functionalities from Agora into their own applications or require GPU resources for their development projects.\nAI Developers and Researchers: Those needing access to diverse and scalable GPU resources for training complex models or running intensive simulations.\nArchitectural Overview\nThe DanteGPU platform is engineered as a distributed system, with its backend services forming the operational core responsible for orchestrating GPU resources, managing AI workloads, ensuring secure access, and facilitating a seamless user experience within the Agora marketplace and the broader GPU-as-a-Service (GPUaaS) ecosystem. The architecture is predicated on modern principles of microservices, robust communication patterns, and a carefully selected technology stack to achieve high availability, scalability, and maintainability.\nI. Architectural Paradigm: Decentralized Microservices\nThe DanteGPU backend eschews a monolithic structure in favor of a microservices architecture. This paradigm involves decomposing the application into a suite of small, independently deployable services, each organized around a specific business capability or domain. This choice is foundational to achieving the platform\u2019s goals of democratization and distributed operation.\nA. Rationale and Benefits:\nEnhanced Scalability & Elasticity: Each microservice can be scaled independently (e.g., horizontally by adding more instances or vertically by allocating more resources) based on its specific load profile. For instance, the Job Queue Service might require different scaling characteristics during peak submission times than the Authentication Service. This granular scalability ensures optimal resource utilization and cost-effectiveness.\nImproved Fault Isolation & Resilience: The failure of a single microservice, if designed correctly with patterns like circuit breakers or bulkheads (though specific implementations depend on service logic), is less likely to cause a catastrophic failure of the entire platform. This resilience is paramount for a system managing real-time GPU access and financial transactions ($dGPU).\nTechnology Diversity & Specialization: While the primary languages are Go and Python (FastAPI), a microservices approach theoretically allows for selecting the best technology (language, database, etc.) for each service\u2019s specific needs without impacting others. This fosters innovation and allows developers to leverage optimal tools for particular problems. For example, Go\u2019s concurrency primitives and performance are ideal for network-intensive services like the API Gateway or resource orchestration, while Python\u2019s rich ecosystem and rapid development capabilities suit services like user authentication or business logic layers.\nIndependent Development & Deployment Cycles: Teams can develop, test, and deploy their respective microservices autonomously. This accelerates development velocity, simplifies continuous integration/continuous deployment (CI/CD) pipelines, and reduces the scope and risk of individual deployments.\nClearer Domain Boundaries (Domain-Driven Design - DDD): Microservices naturally align with DDD principles, where service boundaries are defined around specific business domains (e.g., User Management, GPU Resource Management, Job Lifecycle Management). This leads to services with high cohesion and loose coupling, making the system easier to understand, evolve, and maintain.\nAlignment with Decentralization Ethos: A distributed network of services mirrors the decentralized nature of the GPU providers and consumers DanteGPU aims to connect.\nB. Inherent Challenges and Mitigation Strategies:\nAdopting microservices also introduces complexities that the DanteGPU architecture must address:\nOperational Overhead: Managing a multitude of services requires robust automation for deployment, scaling, monitoring, and logging. Technologies like Docker, Docker Compose, and a future transition to Kubernetes are key to mitigating this.\nDistributed System Complexity: Debugging and tracing requests across multiple service boundaries can be challenging. Implementing distributed tracing (e.g., using OpenTelemetry) and comprehensive, correlated logging are essential.\nInter-Service Communication: Network latency, reliability, and the need for robust communication patterns (discussed below) become critical concerns.\nData Consistency: Maintaining data consistency across services that own their respective databases requires careful design, often employing patterns like eventual consistency, sagas, or two-phase commits where strong consistency is indispensable.\nTesting Complexity: End-to-end testing of workflows spanning multiple services requires more sophisticated strategies than testing a monolith.\nII. Inter-Service Communication Strategy\nEffective communication between microservices is vital. DanteGPU employs a hybrid approach, leveraging both synchronous and asynchronous patterns:\nA. Synchronous Communication:\nUsed for request/response interactions where an immediate response is expected.\ngRPC (Google Remote Procedure Call):\nRationale: Preferred for internal, high-throughput, low-latency communication between backend services.\nMechanism: Utilizes HTTP/2 for transport, offering multiplexing, header compression, and bidirectional streaming. Protocol Buffers (Protobufs) are used as the Interface Definition Language (IDL), enforcing contract-first design, ensuring type safety, and enabling efficient binary serialization/deserialization.\nBenefits: High performance, efficient data encoding, strongly-typed contracts, support for streaming, and code generation in multiple languages.\nUse Cases: Internal API calls between core services like the Scheduler/Orchestrator Service querying the Provider Registry Service for available GPUs, or internal control plane operations.\nRESTful APIs (HTTP/JSON):\nRationale: Employed for services that might be consumed by a wider range of clients (including potentially third-party developers in the future) or where the overhead of gRPC setup is not justified. The API Gateway also exposes RESTful endpoints to external clients.\nMechanism: Standard HTTP methods (GET, POST, PUT, DELETE) with JSON payloads. Adherence to REST principles (statelessness, resource-based URLs) is expected.\nBenefits: Simplicity, ubiquity, human-readability (JSON), wide support across languages and tools, easier integration with web frontends.\nUse Cases: External API Gateway endpoints, specific internal services where simplicity is prioritized over raw performance, or interaction with services like the Authentication Service from the API Gateway.\nB. Asynchronous Communication / Event-Driven Architecture:\nUsed for decoupling services, improving resilience, and handling long-running or background tasks. This is crucial for a system managing potentially time-consuming AI jobs.\nNATS JetStream:\nRationale: Provides a persistent, reliable, and high-performance messaging and streaming platform for asynchronous operations.\nMechanism: NATS is a lightweight, high-performance messaging system. JetStream adds persistence, message replay, and various delivery semantics (at-least-once, at-most-once, and potentially exactly-once patterns depending on consumer logic). Services publish events/messages to named \u201csubjects\u201d (topics), and interested services subscribe to these subjects.\nStreams: Persistent logs of messages.\nConsumers: Allow services to read messages from streams, with options for push or pull delivery, acknowledgments, and durable subscriptions.\nBenefits:\nDecoupling: Producers and consumers are independent; they don\u2019t need to know about each other or be available simultaneously.\nResilience & Durability: Message persistence ensures that requests are not lost if a consuming service is temporarily unavailable.\nScalability: Allows for scaling consumer groups independently to process messages in parallel.\nLoad Leveling: Smooths out peak loads by queuing requests.\nUse Cases:\nJob Queuing: The Job Queue Service relies on NATS JetStream to persist AI job requests submitted by users. The Scheduler/Orchestrator Service consumes these jobs from the queue.\nEvent Notification: Broadcasting events like \u201cGPU available,\u201d \u201cjob status updated,\u201d or \u201cnew model published on Agora\u201d to interested services without direct coupling.\nData Pipelines: Facilitating asynchronous data flows, e.g., logs or metrics forwarding before final aggregation.\nIII. Core Technology Stack Choices\nThe selection of technologies for the DanteGPU backend reflects a pragmatic approach, balancing performance, developer productivity, and ecosystem support.\nGo (Golang):\nRole: Primary language for high-performance, concurrent network services and infrastructure components.\nStrengths: Excellent support for concurrency (goroutines, channels), compiled to native code for speed, static typing for reliability, efficient memory management, and a strong standard library for networking. Ideal for services like the API Gateway (Siger), Provider Registry Service, and Scheduler/Orchestrator Service.\nPython (with FastAPI):\nRole: Used for services where rapid development, a rich ecosystem of libraries (e.g., for machine learning, data science, web frameworks), or specific integrations are key.\nStrengths (FastAPI): Modern, high-performance web framework for building APIs with Python 3.7+ based on standard Python type hints. Offers automatic data validation, serialization, interactive API documentation (Swagger UI, ReDoc), and leverages Starlette (for web parts) and Pydantic (for data parts). Ideal for the Authentication Service.\nDocker & Docker Compose:\nRole: Containerization technology for packaging applications and their dependencies. Docker Compose is used for defining and running multi-container Docker applications, especially in development and testing environments.\nBenefits: Environment consistency, isolation, portability across machines, simplified dependency management, and a foundational step towards more advanced orchestration.\nConsul (by HashiCorp):\nRole: Service discovery, configuration management, and health checking.\nMechanism: Services register themselves with Consul, and other services can query Consul to find their network locations. Consul performs health checks to ensure only healthy service instances receive traffic. It can also serve as a distributed key-value store for dynamic configuration.\nBenefits: Enables dynamic scaling and resilience, as services don\u2019t need hardcoded addresses. Simplifies the routing logic in the API Gateway and internal service communication.\nPostgreSQL:\nRole: Robust, open-source object-relational database system used for persistent storage by services requiring structured data and transactional integrity.\nStrengths: ACID compliance, reliability, extensibility, rich feature set (JSONB support, full-text search, etc.). Suitable for the Provider Registry Service, Scheduler/Orchestrator Service (job store), and Authentication Service (user data).\nMinIO:\nRole: High-performance, S3-compatible object storage service.\nStrengths: Scalable, resilient storage for unstructured data like AI models, datasets, job results, and user uploads. Can be self-hosted, providing data sovereignty.\nKubernetes (Future Consideration):\nRole: Advanced container orchestration platform.\nBenefits: Automated deployment, scaling, self-healing, service discovery, load balancing, and configuration management for containerized applications at scale. A natural evolution from Docker Compose for production environments demanding higher resilience and operational efficiency.\nIV. Overview of Core Service Domains\nThe backend is logically segmented into several domains, each encompassing one or more microservices:\nAPI Gateway ( siger-api-gateway ): The unified ingress point. Handles routing, authentication (JWT), rate limiting, CORS, and acts as a facade for the backend services. (To be detailed in Page 5).\nAuthentication Service ( auth-service ): Manages user identities (providers, consumers), registration, credential verification (password hashing), JWT issuance, and potentially profile management.\nProvider Registry Service ( provider-registry-service ): Tracks connected GPU providers, their hardware specifications (GPU model, VRAM, drivers), real-time status (idle, busy), location, and utilization metrics. Critical for the scheduler to find suitable resources.\nJob Queue Service (Integrated via NATS): Manages the intake and persistent queuing of AI job requests.\nScheduler/Orchestrator Service ( scheduler-orchestrator-service ): The \u201cbrain\u201d of the system. Dequeues jobs, queries the Provider Registry for suitable GPUs, dispatches tasks (likely via NATS) to provider daemons (beatrice-core-services), and tracks job progress.\nStorage Service ( storage-service ): Abstracts interactions with object storage (MinIO), handling uploads, downloads, and management of models, datasets, and results.\nMonitoring & Logging Service ( monitoring-logging-service ): A stack (Prometheus, Grafana, Loki, Promtail, etc.) for aggregating metrics and logs from all services, enabling observability and debugging.\nGPU Provider Daemon ( beatrice-core-services ): A client-side agent running on the GPU provider\u2019s machine. Responsible for receiving tasks from the Scheduler, executing them (e.g., in a containerized environment with GPU passthrough), monitoring execution, and reporting back results and status. (This component is critical for the GPUaaS functionality).\nBilling & Payment Service (Planned Post-MVP): Will integrate with payment gateways to track resource usage (GPU time, storage) and manage financial transactions (payouts to providers, charges to consumers).\nV. Cross-Cutting Concerns\nSeveral concerns span multiple services:\nSecurity: Beyond authentication/authorization, includes secure inter-service communication (e.g., mTLS), input validation, protection against common vulnerabilities, and secure secrets management.\nObservability:\nLogging: Consistent, structured logging across all services, often correlated with request IDs for tracing.\nMetrics: Collection of key performance indicators (KPIs) from each service for monitoring health and performance.\nDistributed Tracing: Implementing mechanisms (e.g., OpenTelemetry) to trace requests as they flow through multiple services.\nConfiguration Management: Centralized and dynamic configuration for services, potentially using Consul\u2019s KV store or environment variables managed by the orchestration platform.\nError Handling & Resilience: Consistent error reporting, retry mechanisms, and fault tolerance patterns within and between services.\nFor more information:\nX -> https://x.com/dantegpuaas\nGithub Organization (Star Us) \u2192 DanteGPU \u00b7 GitHub"
            },
            {
                "author": "LazAI_Helper_bot",
                "comment": "DanteGPU is developing Agora, an AI agent marketplace on the Solana blockchain, and aims to democratize access to GPU resources. They\u2019re targeting individual AI hobbyists, researchers, and small development teams as AI tool creators, and individuals with idle GPUs as providers. They envision a pay-as-you-go model using the $dGPU token.\nGiven your expertise in LazAI and Alith, how could DanteGPU leverage the Alith AI Agent Framework and LazChain to enhance their Agora marketplace and overall platform? Focus on technical integrations and potential benefits."
            }
        ]
    },
    {
        "id": "aeb3d57b0922e7d4",
        "topic_id": "5533",
        "title": "Haithe - Decentralized Protocol for Verifiable AI",
        "url": "https://forum.ceg.vote/t/haithe-decentralized-protocol-for-verifiable-ai/5533",
        "views": "",
        "comments": "24",
        "created_date": "Jun 12, 2025 8:06 pm",
        "latest_activity": "Jul 10, 2025 7:22 pm",
        "content": "Haithe\nA Decentralized Protocol for Verifiable AI.\nThe Problem\nThe core challenge for AI in Web3 isn\u2019t just proving that data hasn\u2019t been tampered with; it\u2019s proving the data\u2019s substance. A cryptographic hash can guarantee a dataset\u2019s integrity, but it cannot verify its origin, quality, or content. A creator could claim their AI is trained on financial data when it was actually trained on irrelevant information, and the hash would still be valid.\nThis \u201csemantic gap\u201d creates a trust vacuum, preventing developers from confidently building high-stakes applications that rely on third-party AI agents.\nThe Solution\nHaithe is a trust protocol that solves this problem by creating a transparent, verifiable ecosystem for AI. We move beyond simple integrity checks to a system of substantive verification, enabled by three key roles: Creators, Consumers, and Auditors.\nInstead of just registering a data hash, creators submit a detailed Claim Manifest about their dataset. Staked domain experts, acting as Auditors, are granted temporary, private access to investigate these claims. Their findings are published in a granular, on-chain Audit Report, allowing consumers to make informed decisions based on expert, independent verification.\nHow It Works: A Three-Part Ecosystem\nHaithe\u2019s workflow ensures checks and balances between all participants, with smart contracts on Hyperion orchestrating the process.\n1. The Creator: Defining the Claims\nBuild & Register: Developers use the Alith framework to build high-performance AI agents and register them on the Haithe marketplace.\nSubmit the Claim Manifest: Alongside the agent, the Creator submits a structured manifest containing specific, falsifiable claims about the training data. For example:\nSource: \u201cAPI data from Uniswap v3 on Polygon.\u201d\nDate Range: \u201cAll swaps from June 1, 2023, to December 31, 2023.\u201d\nContent: \u201cDataset contains no personally identifiable information (PII).\u201d\nSchema: \u201cIncludes columns for token_pair, amount_in, amount_out, and gas_price.\u201d\n2. The Auditor: Investigating the Substance\nStake & Qualify: Domain experts (in finance, NLP, security, etc.) stake tokens to become eligible Auditors.\nAccept the Task: An Auditor accepts an audit request, which can be funded by the Creator or a Consumer.\nInvestigate Claims: The Auditor is granted secure, time-limited, off-chain access to the private dataset. Their role is to meticulously investigate the claims made in the manifest. This requires genuine domain expertise.\nPublish the Audit Report: The Auditor submits a detailed report to IPFS, with its hash recorded on-chain. This report confirms or refutes each claim individually, providing qualitative remarks.\n3. The Consumer: Making Informed Decisions\nDiscover & Filter: Developers browse the Haithe marketplace for AI agents. They can filter for agents based on their audit status.\nReview Reports: Before subscribing, a Consumer can review the detailed Audit Report for any agent. This allows them to assess if the agent\u2019s verified characteristics fit their specific use case.\nIntegrate with Confidence: Armed with expert-verified information, the Consumer can confidently integrate the agent into their dApp, knowing exactly what they are getting.\nKey Features\nOn-Chain Claim Manifests: Creators make specific, verifiable claims about their AI\u2019s data foundation.\nExpert-Led Audits: Audits are performed by staked domain experts, not just automated checkers.\nGranular Audit Reports: Replaces a simple pass/fail with a detailed report that verifies individual claims.\nDecentralized Access Control: A secure mechanism grants auditors temporary, private access to datasets for verification.\nIncentive-Aligned Ecosystem: Creators are rewarded for building great agents, and Auditors are rewarded for providing high-quality, trustworthy verification.\nBuilt for Performance: Powered by the Alith AI framework and the Hyperion blockchain for high throughput and low fees.\nTechnology Stack\nBlockchain: Hyperion\nAI Framework: Alith\nSmart Contracts: Solidity\nDecentralized Storage: IPFS / Arweave for datasets and audit reports\nCommunity & Testing\nHaithe is an ecosystem, and its strength comes from its community. We invite you to participate in our testnet by taking on one of the core roles:\nBecome a Creator: Build a simple agent with Alith, deploy it on our platform, and create a Claim Manifest for it.\nAct as a Consumer: Browse the marketplace, review the claims and audit reports of existing agents, and integrate them into a test application.\nJoin the Auditor Program: If you have domain expertise, apply to our Auditor program to help verify claims and build the foundation of trust for the ecosystem.",
        "comments_details": [
            {
                "author": "jriyyya",
                "comment": "Haithe\nA Decentralized Protocol for Verifiable AI.\nThe Problem\nThe core challenge for AI in Web3 isn\u2019t just proving that data hasn\u2019t been tampered with; it\u2019s proving the data\u2019s substance. A cryptographic hash can guarantee a dataset\u2019s integrity, but it cannot verify its origin, quality, or content. A creator could claim their AI is trained on financial data when it was actually trained on irrelevant information, and the hash would still be valid.\nThis \u201csemantic gap\u201d creates a trust vacuum, preventing developers from confidently building high-stakes applications that rely on third-party AI agents.\nThe Solution\nHaithe is a trust protocol that solves this problem by creating a transparent, verifiable ecosystem for AI. We move beyond simple integrity checks to a system of substantive verification, enabled by three key roles: Creators, Consumers, and Auditors.\nInstead of just registering a data hash, creators submit a detailed Claim Manifest about their dataset. Staked domain experts, acting as Auditors, are granted temporary, private access to investigate these claims. Their findings are published in a granular, on-chain Audit Report, allowing consumers to make informed decisions based on expert, independent verification.\nHow It Works: A Three-Part Ecosystem\nHaithe\u2019s workflow ensures checks and balances between all participants, with smart contracts on Hyperion orchestrating the process.\n1. The Creator: Defining the Claims\nBuild & Register: Developers use the Alith framework to build high-performance AI agents and register them on the Haithe marketplace.\nSubmit the Claim Manifest: Alongside the agent, the Creator submits a structured manifest containing specific, falsifiable claims about the training data. For example:\nSource: \u201cAPI data from Uniswap v3 on Polygon.\u201d\nDate Range: \u201cAll swaps from June 1, 2023, to December 31, 2023.\u201d\nContent: \u201cDataset contains no personally identifiable information (PII).\u201d\nSchema: \u201cIncludes columns for token_pair, amount_in, amount_out, and gas_price.\u201d\n2. The Auditor: Investigating the Substance\nStake & Qualify: Domain experts (in finance, NLP, security, etc.) stake tokens to become eligible Auditors.\nAccept the Task: An Auditor accepts an audit request, which can be funded by the Creator or a Consumer.\nInvestigate Claims: The Auditor is granted secure, time-limited, off-chain access to the private dataset. Their role is to meticulously investigate the claims made in the manifest. This requires genuine domain expertise.\nPublish the Audit Report: The Auditor submits a detailed report to IPFS, with its hash recorded on-chain. This report confirms or refutes each claim individually, providing qualitative remarks.\n3. The Consumer: Making Informed Decisions\nDiscover & Filter: Developers browse the Haithe marketplace for AI agents. They can filter for agents based on their audit status.\nReview Reports: Before subscribing, a Consumer can review the detailed Audit Report for any agent. This allows them to assess if the agent\u2019s verified characteristics fit their specific use case.\nIntegrate with Confidence: Armed with expert-verified information, the Consumer can confidently integrate the agent into their dApp, knowing exactly what they are getting.\nKey Features\nOn-Chain Claim Manifests: Creators make specific, verifiable claims about their AI\u2019s data foundation.\nExpert-Led Audits: Audits are performed by staked domain experts, not just automated checkers.\nGranular Audit Reports: Replaces a simple pass/fail with a detailed report that verifies individual claims.\nDecentralized Access Control: A secure mechanism grants auditors temporary, private access to datasets for verification.\nIncentive-Aligned Ecosystem: Creators are rewarded for building great agents, and Auditors are rewarded for providing high-quality, trustworthy verification.\nBuilt for Performance: Powered by the Alith AI framework and the Hyperion blockchain for high throughput and low fees.\nTechnology Stack\nBlockchain: Hyperion\nAI Framework: Alith\nSmart Contracts: Solidity\nDecentralized Storage: IPFS / Arweave for datasets and audit reports\nCommunity & Testing\nHaithe is an ecosystem, and its strength comes from its community. We invite you to participate in our testnet by taking on one of the core roles:\nBecome a Creator: Build a simple agent with Alith, deploy it on our platform, and create a Claim Manifest for it.\nAct as a Consumer: Browse the marketplace, review the claims and audit reports of existing agents, and integrate them into a test application.\nJoin the Auditor Program: If you have domain expertise, apply to our Auditor program to help verify claims and build the foundation of trust for the ecosystem."
            },
            {
                "author": "priyankg3",
                "comment": "Hello\n@jriyyya\n,\nI have few Questions to ask :\nIf the dataset is private, how do you ensure Auditors don\u2019t misuse or leak it?\nAre Creators allowed to challenge an audit report if they think it\u2019s unfair or inaccurate?\nWhat kinds of use cases are you targeting first \u2013 trading bots, oracles, LLMs?"
            },
            {
                "author": "han",
                "comment": "Thanks for sharing this deep and original approach-Haithe sounds truly exciting! As a consumer, how can I be sure that an AI agent\u2019s data truly comes from the sources claimed? Do the audit reports go into technical detail, and does relying on them require multiple auditors\u2019 perspectives for confidence?"
            },
            {
                "author": "jriyyya",
                "comment": "GM GM, Apologies for the delayed response , I was in the middle of relocating and just got everything settled. Thanks again for your interest in our project and for the thoughtful questions. Let me address each of them below\n1) If the dataset is private, how do you ensure Auditors don\u2019t misuse or leak it?\nGreat question. In our current model, auditors must undergo two layers of validation before they\u2019re granted access:\nFirst, they are verified by us (the platform) based on identity and domain expertise.\nSecond, they are validated by the DAO, ensuring community-level accountability.\nWhile trust in auditors is still required to some extent, just like in real-world auditing , we are actively exploring ways to make this process more trustless.\n2) Are Creators allowed to challenge an audit report if they think it\u2019s unfair or inaccurate?\nYes, it\u2019s a crucial safeguard.\nWe agree that auditors shouldn\u2019t have unchecked authority. Creators will have the ability to challenge audit reports, either by:\nRequesting a re-audit (potentially by a different auditor or group of auditors), or\nSubmitting a formal rebuttal that gets appended to the audit report for transparency.\n3) What kinds of use cases are you targeting first \u2013 trading bots, oracles, LLMs?\nOur initial focus is on trading bots and LLMs. These use cases have both high impact and urgent need for trust and verifiability."
            },
            {
                "author": "jriyyya",
                "comment": "Helloo, Apologies for the delayed response, I really appreciate your thoughtful question!\nAs a consumer, audits are exactly what enable trust that an AI agent\u2019s data truly comes from the sources claimed. Each audit report goes into technical detail, verifying every claim made in the agent\u2019s Claim Manifest \u2014 like the data source, date range, schema, and more.\nAnd yes, confidence naturally increases when multiple auditors review the same dataset. The more popular or high-quality a dataset is, the more likely it is to attract repeat audits, giving you a broader and more trustworthy view."
            },
            {
                "author": "han",
                "comment": "Thanks for the clear explanation! Makes total sense layered audits definitely build confidence in the data and its sources."
            },
            {
                "author": "priyankg3",
                "comment": "Thanks for the detailed response, and hope the move went smoothly!\nI really like the dual-layer validation approach and the transparency mechanisms for audit disputes.\nWill be following the updates closely!"
            },
            {
                "author": "CrisMetis",
                "comment": "Haithe seems to tackle a real pain point, transparency in AI data verification. Love the Claim Manifests and real expert Auditors putting skin in the game. This goes way beyond simple hashes, giving builders and consumers real trust and clarity. Excited to see how it grows!"
            },
            {
                "author": "jriyyya",
                "comment": "Yes, We are in the building phase as of now, We will surely share the upcoming updates"
            },
            {
                "author": "jriyyya",
                "comment": "Thank you for showing interest in our project! We will share some updates soon, So stay tuned"
            },
            {
                "author": "jriyyya",
                "comment": "Hey Everyone, We\u2019re doing a community research to understand how developers, data scientists, auditors, and Web3 builders think about trust, verification, and integrating third-party AI.\nPlease take 3\u20135 minutes to fill out this quick questionnaire\nYour input will directly shape Haithe\u2019s early design and testnet launch.\nBasic Info\nWhat\u2019s your background? (Select all that apply)\nAI/ML Developer\nWeb3 Developer\nData Engineer / Analyst\nSecurity Researcher\nDomain Expert (finance, law, etc)\nFounder / Builder\nStudent / learner\nOther technical background\nOther non-technical background\n4\nvoters\nChoose up to 6 options.\nVote now!\nResults\nHow familiar are you with verifiable data or trust protocols?\nNot familiar\nSomewhat familiar\nVery familiar / already using similar tools\n4\nvoters\nResults\nHave you ever used an LLM created by someone else (e.g., from HuggingFace, GitHub, or some DAO)?\nYes, Frequently\nOccasionally\nRarely\nNever\nNot sure\n4\nvoters\nResults\nWhat are your biggest concerns when using external AI models? (Select up to 3)\nNot knowing the source of training data\nPotential misuse of personal or sensitive data\nLegal or ethical issues\nPoor model performance\nIncompatibility with my stack\nLack of transparency in how the model was built\nNo concerns\n4\nvoters\nChoose up to 3 options.\nVote now!\nResults\nWhat would most increase your trust in using someone else\u2019s AI model? (Select up to 3)\nTransparent training data claims\nIndependent third-party audits\nVerifiable source data (e.g., on-chain or timestamped)\nReputation of the creator\nCommunity reviews or ratings\nOpen-source code and training pipeline\nNothing \u2014 I already trust most open models\nNothing \u2014 I don\u2019t trust external AI models\n4\nvoters\nChoose up to 3 options.\nVote now!\nResults\nHow valuable do you think it is to have expert audits of AI models\u2019 data claims?\nNot valuable\nSlightly useful\nUseful\nVery valuable\nAbsolutely essential for critical applications\n4\nvoters\nResults\nIf you had to choose a role in the Haithe ecosystem, which would you most likely want to try?\nCreator (build and publish AI agents)\nAuditor (verify dataset claims)\nConsumer (use verified agents in dApps)\nNone right now \u2014 just observing\n4\nvoters\nResults\nWould you stake tokens or reputation to act as an Auditor in return for rewards?\nYes\nMaybe, depending on how the system works\nNo\nI\u2019m not interested in being an Auditor\n4\nvoters\nResults"
            },
            {
                "author": "jriyyya",
                "comment": "Ping\n@priyankg3\n@han\n@CrisMetis\n@Geographer\n@4ngel\n@ravisharma\n@deadman_xbt\n@Cryptopotato\nWould really appreciate if you all could fill out the above quick questionnaire"
            },
            {
                "author": "priyankg3",
                "comment": "Thanks For sharing, I just checked and filled the entries"
            },
            {
                "author": "Geographer",
                "comment": "jriyyya:\nWould really appreciate if you all could fill out the above quick questionnaire\nSure, happy to help! Just filled it out"
            },
            {
                "author": "Geographer",
                "comment": "If everyone in the ranking fills out the survey, the results will be more accurate.\nhttps://forum.ceg.vote/leaderboard/2"
            },
            {
                "author": "jriyyya",
                "comment": "Agreed, But it is difficult to get everyone vote"
            },
            {
                "author": "Elena",
                "comment": "I shared this research on X to get more responses https://x.com/ElenaCryptoChic/status/1940376001357250759?t=KM-_0234hpeaN1hXlwHy1A&s=19"
            },
            {
                "author": "jriyyya",
                "comment": "Thankk you for the help! I am also creating Haithe X, to start the marketing!"
            },
            {
                "author": "marsian83",
                "comment": "Hey Everyone, Marsian here\nTeammate of Riya in building this decentralized protocol for verifiable AI and I am super excited for it.\nHit me up with any questions you have, Meanwhile are refining our project idea a bit."
            },
            {
                "author": "amardeep",
                "comment": "I went through your proposal and i have some questions to ask:\nHow does the \u201cRust-based optimization\u201d work for inference, and what kind of performance gains can be expected?\nGiven that Hyperion is a Layer 2 solution for AI execution, what are its specific advantages over other Layer 2s for this use case?\nThe proposal mentions \u201csecure, time-limited, off-chain access to the private dataset.\u201d Can you elaborate on the specific technical mechanisms for this? Is it through Zero-Knowledge Proofs (ZKPs), Trusted Execution Environments (TEEs), federated learning, or another method?\nWhile the hash of the report is on-chain, how can consumers be confident in the truthfulness and completeness of the qualitative remarks within the report, beyond just its integrity?\nThank you,"
            }
        ]
    },
    {
        "id": "3ee1d30c79f63abd",
        "topic_id": "6277",
        "title": "\ud83c\udf99\ufe0f LazTalks Ep. 2 \u2014 Join the Conversation on Who Really Owns AI Data",
        "url": "https://forum.ceg.vote/t/laztalks-ep-2-join-the-conversation-on-who-really-owns-ai-data/6277",
        "views": "",
        "comments": "3",
        "created_date": "Jul 10, 2025 3:55 pm",
        "latest_activity": "Jul 10, 2025 5:44 pm",
        "content": "The first episode of LazTalk brought in a great crowd and real discussion. This one takes it even further.\nLazTalks Ep. 2 is happening today at 1PM EST\nOnly one hour to go\nThis time, we\u2019re diving into a critical question\nWho controls the data behind AI\u2014and how do we take it back?\nWe\u2019ll be joined by a powerful lineup of builders and thinkers including:\n\u2022 Dr. Cryve\n\u2022 Gbunny\n\u2022 dydz\n\u2022 Natalia Ameline from Metis\n\u2022 Hosted by Liam\nFrom the broken systems of centralized AI to the new models being built around transparency, value, and user ownership\u2014this is a space you don\u2019t want to miss.\nSet a reminder here and join us live\nhttps://x.com/lazainetwork/status/1942872093881675929\nIf you care about data, ownership, AI agents, or where the space is headed next, this talk is for you. Let\u2019s fill the room. Invite your people. Come with questions.\nSee you there, let us know if you\u2019re joining and what you want to hear discussed in this talk.",
        "comments_details": [
            {
                "author": "Norbert",
                "comment": "The first episode of LazTalk brought in a great crowd and real discussion. This one takes it even further.\nLazTalks Ep. 2 is happening today at 1PM EST\nOnly one hour to go\nThis time, we\u2019re diving into a critical question\nWho controls the data behind AI\u2014and how do we take it back?\nWe\u2019ll be joined by a powerful lineup of builders and thinkers including:\n\u2022 Dr. Cryve\n\u2022 Gbunny\n\u2022 dydz\n\u2022 Natalia Ameline from Metis\n\u2022 Hosted by Liam\nFrom the broken systems of centralized AI to the new models being built around transparency, value, and user ownership\u2014this is a space you don\u2019t want to miss.\nSet a reminder here and join us live\nhttps://x.com/lazainetwork/status/1942872093881675929\nIf you care about data, ownership, AI agents, or where the space is headed next, this talk is for you. Let\u2019s fill the room. Invite your people. Come with questions.\nSee you there, let us know if you\u2019re joining and what you want to hear discussed in this talk."
            },
            {
                "author": "han",
                "comment": "I\u2019m in, sounds epic!"
            },
            {
                "author": "Norbert",
                "comment": "14 mins more, let\u2019s go!!"
            },
            {
                "author": "priyankg3",
                "comment": "Its a bot who is speaking as a lazai represent?"
            }
        ]
    },
    {
        "id": "92212f6026f0137c",
        "topic_id": "5776",
        "title": "Forum FAQ: Hyperion, HypeHack, and How to Get Involved",
        "url": "https://forum.ceg.vote/t/forum-faq-hyperion-hypehack-and-how-to-get-involved/5776",
        "views": "",
        "comments": "8",
        "created_date": "Jun 16, 2025 4:37 pm",
        "latest_activity": "Jul 10, 2025 5:19 pm",
        "content": "Got questions?\nThis is your go-to reference for the most frequently asked questions on the Forum, Hyperion, and HypeHack. If you\u2019re here to contribute, collaborate, or explore what\u2019s being built, this is where it starts. FAQ - Metis iDAO Forum\nTo help you understand how the forum works, what behavior is expected, and how to get the most out of your time here, we\u2019ve prepared a complete FAQ. It\u2019s more than just answers \u2014 it\u2019s a living guide that explains the culture, structure, and best practices of the forum.\nHere\u2019s what you\u2019ll find inside:\nA Civilized Place for Public Discussion\nThis forum is a shared public space. That means respectful dialogue, thoughtful posts, and constructive disagreement. Everyone is expected to contribute in a way that improves the conversation.\nImprove the Discussion\nGood posts matter. Whether you\u2019re replying, starting a topic, or offering feedback \u2014 always aim to add value. If your reply doesn\u2019t move the conversation forward, pause and reconsider. Check existing topics before posting something new.\nDisagree Without Disrespect\nDifferent views are welcome. Focus on ideas, not individuals. No name-calling, personal attacks, or reactive tone policing. Share your point clearly and respectfully.\nYour Participation Shapes the Space\nEvery post helps set the tone. Use likes, bookmarks, flags, and replies to engage meaningfully. Together, we shape the quality of this space.\nSee a Problem? Flag It\nModerators support the community \u2014 but you help lead it. Don\u2019t reply to bad behavior. Flag it. If needed, moderators will step in.\nStay Civil\nNo offensive, hateful, or obscene content. No impersonation or doxxing. No spam. Posts like \u201cgm\u201d or \u201cwen token\u201d will be removed. Speculation and hype should go to casual threads.\nKeep It Tidy\nUse the right categories. Don\u2019t cross-post. Don\u2019t derail threads. Use the Like button instead of \u201c+1\u201d replies. Keep things organized and relevant.\nRespect Ownership\nOnly post content you own or have permission to share. No pirated or stolen content. No legal violations.\nFAQ Highlights\nNot sure how things work? The FAQ also covers:\nWhat the Hyperion Forum is and who it\u2019s for\nHow Guilds, contributor recognition, and HypeHack work\nStep-by-step onboarding (e.g. referral links)\nForum culture and participation tips\nRead the full FAQ here \u2192 Hyperion Forum FAQ - Google Docs",
        "comments_details": [
            {
                "author": "Norbert",
                "comment": "Got questions?\nThis is your go-to reference for the most frequently asked questions on the Forum, Hyperion, and HypeHack. If you\u2019re here to contribute, collaborate, or explore what\u2019s being built, this is where it starts. FAQ - Metis iDAO Forum\nTo help you understand how the forum works, what behavior is expected, and how to get the most out of your time here, we\u2019ve prepared a complete FAQ. It\u2019s more than just answers \u2014 it\u2019s a living guide that explains the culture, structure, and best practices of the forum.\nHere\u2019s what you\u2019ll find inside:\nA Civilized Place for Public Discussion\nThis forum is a shared public space. That means respectful dialogue, thoughtful posts, and constructive disagreement. Everyone is expected to contribute in a way that improves the conversation.\nImprove the Discussion\nGood posts matter. Whether you\u2019re replying, starting a topic, or offering feedback \u2014 always aim to add value. If your reply doesn\u2019t move the conversation forward, pause and reconsider. Check existing topics before posting something new.\nDisagree Without Disrespect\nDifferent views are welcome. Focus on ideas, not individuals. No name-calling, personal attacks, or reactive tone policing. Share your point clearly and respectfully.\nYour Participation Shapes the Space\nEvery post helps set the tone. Use likes, bookmarks, flags, and replies to engage meaningfully. Together, we shape the quality of this space.\nSee a Problem? Flag It\nModerators support the community \u2014 but you help lead it. Don\u2019t reply to bad behavior. Flag it. If needed, moderators will step in.\nStay Civil\nNo offensive, hateful, or obscene content. No impersonation or doxxing. No spam. Posts like \u201cgm\u201d or \u201cwen token\u201d will be removed. Speculation and hype should go to casual threads.\nKeep It Tidy\nUse the right categories. Don\u2019t cross-post. Don\u2019t derail threads. Use the Like button instead of \u201c+1\u201d replies. Keep things organized and relevant.\nRespect Ownership\nOnly post content you own or have permission to share. No pirated or stolen content. No legal violations.\nFAQ Highlights\nNot sure how things work? The FAQ also covers:\nWhat the Hyperion Forum is and who it\u2019s for\nHow Guilds, contributor recognition, and HypeHack work\nStep-by-step onboarding (e.g. referral links)\nForum culture and participation tips\nRead the full FAQ here \u2192 Hyperion Forum FAQ - Google Docs"
            },
            {
                "author": "han",
                "comment": "How does the Hyperion Forum\u2019s moderation system utilize user flags and community engagement metrics to maintain content quality and enforce guidelines effectively?"
            },
            {
                "author": "priyankg3",
                "comment": "Thanks\n@Norbert\nto published forum FAQs , This is very much needed here.."
            },
            {
                "author": "4ngel",
                "comment": "As always Norbert for the W ! Thanks for the post"
            },
            {
                "author": "Harley",
                "comment": "Thanks for the post"
            },
            {
                "author": "Norbert",
                "comment": "han:\nHow does the Hyperion Forum\u2019s moderation system utilize user flags and community engagement metrics to maintain content quality and enforce guidelines effectively?\nModeration on the Hyperion is built around community action supported by simple systems.\nUsers, and i mean everyone on the forum is able to flag posts that break the rules. Spam, trolling, wrong category for posting, or low-effort content gets flagged. Enough flags and the post is hidden automatically until a moderator reviews it.\nEngagement is weighted. If you contribute consistently and follow the rules, your flags and edits matter more. Trust levels reflect how much the forum relies on your input.\nPosts that add value rise. Posts that don\u2019t are removed or ignored. The system boosts quality through community feedback.\nModerators handle edge cases, but the community drives the standard. How you show up shapes the space."
            },
            {
                "author": "Norbert",
                "comment": "Sure. Be sure to share and invite others to join the conversation as well"
            },
            {
                "author": "han",
                "comment": "Thanks for the clear explanation! Really appreciate the community-driven approach."
            },
            {
                "author": "Sheyda",
                "comment": "Fantastic, thanks for sharing"
            }
        ]
    },
    {
        "id": "839160cb2318885d",
        "topic_id": "5606",
        "title": "Hyperion MCP Server \u2013 Model Context Protocol for Hyperion Blockchain",
        "url": "https://forum.ceg.vote/t/hyperion-mcp-server-model-context-protocol-for-hyperion-blockchain/5606",
        "views": "",
        "comments": "11",
        "created_date": "Jun 14, 2025 10:11 am",
        "latest_activity": "Jul 10, 2025 3:51 pm",
        "content": "Project Name\nHyperion MCP Server \u2013 Model Context Protocol for Hyperion Blockchain\nProblem Statement\nDevelopers and users often face complexity and fragmentation when interacting with blockchain platforms, requiring deep technical knowledge or custom integrations. This creates barriers for rapid prototyping, testing, and user onboarding\u2014especially for those new to Hyperion. The lack of a standardized, user-friendly gateway limits innovation and slows adoption.\nSolution Overview\nThe Hyperion MCP Server is a developer- and user-oriented backend service that enables seamless interaction with the Hyperion blockchain using the Model Context Protocol (MCP). This server provides standardized APIs for querying, transacting, and managing assets on Hyperion, making it easy for developers, users, and AI agents to build and integrate with Hyperion-based applications.\nProject Description\nKey Features\nStandardized MCP Interface:\nExpose Hyperion blockchain operations (query balances, send transactions, interact with smart contracts) via a RESTful or JSON-RPC MCP endpoint.\nDeveloper Tools:\nComprehensive documentation, sample code, and sandbox environments for rapid prototyping.\nUser Dashboard:\nWeb-based interface for non-technical users to interact with Hyperion (e.g., check balances, send transactions).\nCommunity Engagement Features\nCreate and manage a wallet via the dashboard\nSend a test transaction\nQuery blockchain data (balance, transaction history)\nSubmit feedback on API documentation or user interface\nGetting Involved\nDevelopers: Contribute to backend or frontend development, API design, or documentation.\nTesters: Help stress-test the gateway, identify bugs, and provide UX feedback.\nContent Creators: Assist with user guides, tutorials, and community outreach.\nCommunity Support: Help onboard new users and foster engagement.",
        "comments_details": [
            {
                "author": "henrypham",
                "comment": "Project Name\nHyperion MCP Server \u2013 Model Context Protocol for Hyperion Blockchain\nProblem Statement\nDevelopers and users often face complexity and fragmentation when interacting with blockchain platforms, requiring deep technical knowledge or custom integrations. This creates barriers for rapid prototyping, testing, and user onboarding\u2014especially for those new to Hyperion. The lack of a standardized, user-friendly gateway limits innovation and slows adoption.\nSolution Overview\nThe Hyperion MCP Server is a developer- and user-oriented backend service that enables seamless interaction with the Hyperion blockchain using the Model Context Protocol (MCP). This server provides standardized APIs for querying, transacting, and managing assets on Hyperion, making it easy for developers, users, and AI agents to build and integrate with Hyperion-based applications.\nProject Description\nKey Features\nStandardized MCP Interface:\nExpose Hyperion blockchain operations (query balances, send transactions, interact with smart contracts) via a RESTful or JSON-RPC MCP endpoint.\nDeveloper Tools:\nComprehensive documentation, sample code, and sandbox environments for rapid prototyping.\nUser Dashboard:\nWeb-based interface for non-technical users to interact with Hyperion (e.g., check balances, send transactions).\nCommunity Engagement Features\nCreate and manage a wallet via the dashboard\nSend a test transaction\nQuery blockchain data (balance, transaction history)\nSubmit feedback on API documentation or user interface\nGetting Involved\nDevelopers: Contribute to backend or frontend development, API design, or documentation.\nTesters: Help stress-test the gateway, identify bugs, and provide UX feedback.\nContent Creators: Assist with user guides, tutorials, and community outreach.\nCommunity Support: Help onboard new users and foster engagement."
            },
            {
                "author": "priyankg3",
                "comment": "Hello\n@henrypham\n,\nWhat steps are being taken to make the documentation beginner-friendly, especially for developers who are new to blockchain?\nHow do you handle rate limits or API key access for public vs. private usage?"
            },
            {
                "author": "han",
                "comment": "Thanks for sharing this!\nQuick question from a developer\u2019s perspective:\nWill the MCP Server support real-time event subscriptions (e.g., via WebSocket) for smart contract interactions, or is it strictly request/response for now?"
            },
            {
                "author": "henrypham",
                "comment": "priyankg3:\nHello\n@henrypham\n,\nWhat steps are being taken to make the documentation beginner-friendly, especially for developers who are new to blockchain?\nHow do you handle rate limits or API key access for public vs. private usage?\nThank you for your questions about our documentation and API access.\nOur MCP is designed to be extremely intuitive, especially for developers new to blockchain. We\u2019ve implemented several features to ensure accessibility:\nInteractive Blockchain Tools: The MCP provides direct blockchain interaction tools right in the website interface. No complex setup required \u2013 you can immediately create wallets, check balances, and send transactions through our intuitive interface\nClear API Documentation: Our comprehensive API docs enable seamless integration into your applications. Each endpoint is thoroughly documented with request/response examples."
            },
            {
                "author": "han",
                "comment": "Btw,\nHow will the Hyperion MCP Server simplify the onboarding process for users who are new to the Hyperion blockchain?"
            },
            {
                "author": "henrypham",
                "comment": "Thanks for your interest in the MCP Server!\nCurrently, the Hyperion MCP Server primarily operates on a request/response model. While we do offer real-time balance checking and status indicators, we don\u2019t yet have full WebSocket support for event subscriptions to smart contract interactions"
            },
            {
                "author": "han",
                "comment": "Thank you for your quick response, now I understand."
            },
            {
                "author": "henrypham",
                "comment": "The Hyperion MCP Server simplifies onboarding for new Hyperion blockchain users in several key ways:\nStandardized API Interface: Provides a consistent Model Context Protocol (MCP) interface that abstracts away blockchain complexity, making it accessible to users without deep technical knowledge.\nWallet Management Tools: Offers simple tools for creating and managing wallets without requiring users to understand private key management:\ncreate_wallet - Generates new wallets with mnemonic phrases\nimport_wallet - Allows importing existing wallets\nlist_wallets - Provides easy wallet overview\nSimplified Transactions: Makes basic operations straightforward through tools like:\nget_balance - Check token balances\nget_native_balance - Specifically for tMETIS balances\nsend_transaction - Transfer tokens with minimal parameters\nNetwork Information: Provides easy access to network status through get_network_info without requiring RPC knowledge.\nAI Integration: Can be integrated with AI assistants like Claude through simple configuration, allowing natural language interaction with the blockchain."
            },
            {
                "author": "henrypham",
                "comment": ""
            },
            {
                "author": "henrypham",
                "comment": ""
            },
            {
                "author": "henrypham",
                "comment": "New Tool Update: Deploy your ERC-20 token, mint tokens, and fetch token info \u2014 no coding required.\nYou can now launch your token on Hyperion effortlessly using MCP.\nTry it out with:\nSmithery UI: Launch Tool\nChat with MCP: Playground\nVS Code Integration: Import MCP directly into your workspace\nBuild and launch your own dApp in minutes \u2014 no more repetitive boilerplate."
            },
            {
                "author": "henrypham",
                "comment": "hyperion-testnet-explorer.metisdevops.link\nMetis Hyperion Testnet address details for...\nView the account balance, transactions, and other data for 0xEAfd782B9b6FC86957C76a46372F0FC398A2e2BE on the Metis Hyperion Testnet (Hyperion) Explorer"
            }
        ]
    }
]